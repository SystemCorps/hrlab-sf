{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Trainig Templete\n",
    "## Based on Tensorlfow - CNN MNIST example\n",
    "https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/examples/tutorials/layers/cnn_mnist.py\n",
    "\n",
    "Tapping modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 library 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model 설계\n",
    "현재는 MNIST에 사용된 것으로, 추후 그물 찢김에 적용하기 위해 수정 필요\n",
    "\n",
    "### Input Layer\n",
    "Input Image Pixel: 28x28  \n",
    "Color channel: 1 (grayscale)  \n",
    "\n",
    "### 1st Conv Layer\n",
    "Num of filter: 32  \n",
    "Kernel size: 5x5  \n",
    "Padding: Same  \n",
    "Activation: ReLU  \n",
    "Padding same은 입/출력이 같은 크기를 갖도록 padding하는 것  \n",
    "\n",
    "### 1st Pooling Layer\n",
    "Max pooling  \n",
    "Size: 2x2  \n",
    "Stride: 2  \n",
    "Max pooling 시 size의 폭과 stride가 같으면 pooling window가 서로 겹치지 않음  \n",
    "\n",
    "### 2nd Conv Layer\n",
    "Num of filter: 64  \n",
    "Kernel size: 5x5  \n",
    "Padding: Same  \n",
    "Activation: ReLU  \n",
    "\n",
    "### 2nd Pooling Layer\n",
    "Max pooling  \n",
    "Size: 2x2  \n",
    "Stride: 2  \n",
    "\n",
    "### Dense Layer\n",
    "Fully connected  \n",
    "\n",
    "### Drop out\n",
    "Rate: 0.4 (40%)  \n",
    "훈련 중 40%의 connection이 임의로 제거됨  \n",
    "Overfitting 방지  \n",
    "뇌의학에서도 학습을 반복할수록 사람 뇌의 뉴런은 일부 connection이 끊어지면서 더 확실하게 학습한다고 함  \n",
    "\n",
    "### Logits Layer\n",
    "Output node: 10  \n",
    "숫자 0~9까지 classification\n",
    "\n",
    "### Training\n",
    "Loss function: Softmax Cross Entropy  \n",
    "Optimizer: Gradient Descent  \n",
    "Learning rate: 0.001  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Run\n",
    "MNIST data 다운로드  \n",
    "\n",
    "### Training\n",
    "Batch size: 100  \n",
    "Epoch: 0  \n",
    "Shuffle: True  \n",
    "Step: 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    # Load training and eval data\n",
    "    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "    train_data = mnist.train.images  # Returns np.array\n",
    "    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "    eval_data = mnist.test.images  # Returns np.array\n",
    "    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "    # Create the Estimator\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "        model_fn=cnn_model_fn, model_dir=\"./MNIST_Test\")\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=100,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    mnist_classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=20000,\n",
    "        hooks=[logging_hook])\n",
    "\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_data},\n",
    "        y=eval_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-4-13970e3f79bb>:3: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './MNIST_Test', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x127be5160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./MNIST_Test/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.11184727 0.09945039 0.11790627 0.09456728 0.10997335 0.09061773\n",
      "  0.09984353 0.07796806 0.09245268 0.10537344]\n",
      " [0.07912653 0.11726119 0.11358055 0.11689231 0.09973546 0.09639318\n",
      "  0.10102662 0.09480047 0.09036409 0.09081966]\n",
      " [0.08869739 0.09927983 0.09266704 0.12399039 0.09718635 0.10560697\n",
      "  0.10279394 0.09676628 0.09042287 0.10258889]\n",
      " [0.10483562 0.10972264 0.112646   0.11089513 0.08755841 0.09432083\n",
      "  0.12115712 0.08392179 0.07650186 0.09844058]\n",
      " [0.08137877 0.12464077 0.10959332 0.09628224 0.10159501 0.0980432\n",
      "  0.09740367 0.09635054 0.09299902 0.10171339]\n",
      " [0.10874169 0.10905729 0.09132248 0.10479485 0.11305521 0.09907784\n",
      "  0.09488824 0.09020536 0.08821024 0.10064685]\n",
      " [0.08883164 0.09776849 0.10523111 0.11165638 0.10858431 0.09518961\n",
      "  0.10117419 0.1026421  0.08645978 0.10246243]\n",
      " [0.09038319 0.11253025 0.09130903 0.11928788 0.10144583 0.09353875\n",
      "  0.10740153 0.10129082 0.09210762 0.09070501]\n",
      " [0.08326975 0.10254622 0.11062387 0.11023018 0.10766019 0.1057544\n",
      "  0.10817076 0.09214978 0.08863224 0.09096265]\n",
      " [0.0974542  0.12138063 0.10895117 0.10407985 0.09949924 0.09869742\n",
      "  0.10342022 0.08694738 0.08397056 0.09559938]\n",
      " [0.10689612 0.0889674  0.09746052 0.11096491 0.09719666 0.10932042\n",
      "  0.09705622 0.09998312 0.09697138 0.09518327]\n",
      " [0.09702507 0.10149148 0.11468033 0.10111667 0.12408444 0.10624495\n",
      "  0.09920713 0.08820438 0.0832248  0.08472087]\n",
      " [0.08686622 0.11096565 0.10598896 0.11194614 0.09639271 0.089557\n",
      "  0.10618323 0.09661422 0.0991544  0.09633149]\n",
      " [0.08839228 0.10879561 0.11272405 0.10933121 0.1038477  0.09324246\n",
      "  0.10582891 0.10356927 0.07709452 0.09717404]\n",
      " [0.09652409 0.09457513 0.09348279 0.10818132 0.09462003 0.10347139\n",
      "  0.10335317 0.09660825 0.10201111 0.10717279]\n",
      " [0.09384809 0.10629547 0.10719825 0.12360389 0.1058127  0.10801464\n",
      "  0.08920125 0.08773034 0.09663931 0.08165614]\n",
      " [0.08098946 0.11404628 0.11182334 0.10876887 0.1069834  0.09868255\n",
      "  0.0978472  0.09642237 0.08934788 0.09508863]\n",
      " [0.09670871 0.10352832 0.10167976 0.10615674 0.10732791 0.10964315\n",
      "  0.10882241 0.08386326 0.09384376 0.08842596]\n",
      " [0.08935814 0.09666865 0.09395607 0.11449482 0.10254917 0.10394503\n",
      "  0.10581628 0.09493046 0.08773492 0.11054649]\n",
      " [0.0876279  0.09933011 0.10138663 0.11988103 0.111487   0.09744331\n",
      "  0.09327821 0.09712078 0.09626004 0.096185  ]\n",
      " [0.09388996 0.09904437 0.08849988 0.1181272  0.11092877 0.09795237\n",
      "  0.10681    0.09819651 0.09192277 0.09462809]\n",
      " [0.10037045 0.10063293 0.10592459 0.11589728 0.11684073 0.10049016\n",
      "  0.09271985 0.09639014 0.07781284 0.09292101]\n",
      " [0.09164478 0.11667302 0.10854643 0.10703819 0.10435311 0.09898696\n",
      "  0.09849209 0.09070864 0.09570228 0.08785443]\n",
      " [0.1035364  0.09930925 0.10424343 0.11217984 0.10812855 0.08973469\n",
      "  0.09249695 0.0983462  0.08691665 0.10510805]\n",
      " [0.10854752 0.11596044 0.09384675 0.10106745 0.09916005 0.08802882\n",
      "  0.11275408 0.09886043 0.0876594  0.09411512]\n",
      " [0.09898821 0.1098502  0.11042408 0.09956725 0.10507322 0.0978447\n",
      "  0.09146031 0.09670985 0.09079688 0.09928527]\n",
      " [0.09803526 0.09830342 0.10738397 0.10034348 0.11307772 0.09409947\n",
      "  0.10536323 0.10379583 0.07810587 0.10149173]\n",
      " [0.10948129 0.12571266 0.1053627  0.10100684 0.09405682 0.08652101\n",
      "  0.10672569 0.08785424 0.09018765 0.09309111]\n",
      " [0.0858973  0.11245747 0.11052608 0.11847439 0.11935697 0.08599991\n",
      "  0.10724748 0.08232909 0.10006327 0.07764801]\n",
      " [0.09499323 0.09695063 0.09737053 0.11901315 0.09475415 0.10039164\n",
      "  0.11189175 0.10753702 0.0871039  0.08999405]\n",
      " [0.08792882 0.10187784 0.09736288 0.11103231 0.10180394 0.10215364\n",
      "  0.11328229 0.0979356  0.08901735 0.09760538]\n",
      " [0.09452659 0.11636627 0.10754529 0.11646319 0.1040799  0.09081258\n",
      "  0.11059424 0.08184492 0.0902852  0.08748186]\n",
      " [0.09590444 0.1006825  0.10102747 0.11540724 0.10466699 0.0851834\n",
      "  0.10946403 0.09744462 0.08745498 0.10276432]\n",
      " [0.09391317 0.0990461  0.10648018 0.09700138 0.11220349 0.10852288\n",
      "  0.09958569 0.09561484 0.08801468 0.09961758]\n",
      " [0.09329111 0.106258   0.11188064 0.10105905 0.08785551 0.10817137\n",
      "  0.11160236 0.09682977 0.0881408  0.0949114 ]\n",
      " [0.09118666 0.09846282 0.10709676 0.12079585 0.1000962  0.10570936\n",
      "  0.09868038 0.08577054 0.09805353 0.09414785]\n",
      " [0.10758542 0.11675625 0.10874214 0.11049638 0.09603221 0.09726711\n",
      "  0.10093712 0.08185263 0.09132562 0.08900511]\n",
      " [0.10020344 0.10513603 0.11027145 0.11508206 0.09669577 0.09835707\n",
      "  0.08719528 0.09835135 0.09263198 0.09607556]\n",
      " [0.09418903 0.09342314 0.10394555 0.10102537 0.11413188 0.1087591\n",
      "  0.09616932 0.10238453 0.09678434 0.0891877 ]\n",
      " [0.08932074 0.10972807 0.10422241 0.11118072 0.11445779 0.0876678\n",
      "  0.08917861 0.10476813 0.09650062 0.09297517]\n",
      " [0.10071611 0.09776068 0.11263209 0.10965862 0.10589915 0.10188395\n",
      "  0.08406711 0.08704366 0.09578996 0.10454874]\n",
      " [0.09379641 0.10786659 0.09262449 0.1080998  0.09293786 0.10506201\n",
      "  0.10750091 0.099663   0.09430315 0.09814581]\n",
      " [0.08386061 0.1134147  0.11368605 0.09823471 0.09423611 0.11721206\n",
      "  0.1027225  0.08785138 0.08706743 0.10171445]\n",
      " [0.0888956  0.09934262 0.09547549 0.09918472 0.10607268 0.10005739\n",
      "  0.10711612 0.10044815 0.09240827 0.11099903]\n",
      " [0.09923904 0.10854346 0.09843716 0.10082639 0.10798724 0.09358977\n",
      "  0.09811384 0.10086456 0.09008097 0.10231765]\n",
      " [0.09224812 0.09498035 0.09925783 0.10166784 0.10122131 0.10499858\n",
      "  0.10626441 0.09775225 0.09703688 0.10457239]\n",
      " [0.09645855 0.12212921 0.09005738 0.10843292 0.10417794 0.09641106\n",
      "  0.10460642 0.10447501 0.08529475 0.08795667]\n",
      " [0.10592373 0.10085712 0.11662878 0.09568244 0.08928417 0.11191963\n",
      "  0.08870244 0.09228338 0.10050569 0.09821268]\n",
      " [0.0939628  0.11296779 0.09612241 0.12351386 0.09556799 0.10623541\n",
      "  0.10693281 0.0875103  0.089773   0.08741363]\n",
      " [0.08674353 0.11338319 0.10969586 0.11578441 0.09197506 0.09272561\n",
      "  0.11517804 0.09029832 0.08485228 0.0993637 ]\n",
      " [0.07854021 0.10582591 0.11172083 0.10806183 0.11799449 0.09270874\n",
      "  0.11643637 0.09060846 0.08478289 0.09332026]\n",
      " [0.10852443 0.1102476  0.09646094 0.10323439 0.10548098 0.09474901\n",
      "  0.1077738  0.09628413 0.08833504 0.08890968]\n",
      " [0.08098551 0.10179852 0.08592847 0.11460659 0.10646252 0.09757104\n",
      "  0.10798533 0.09693111 0.1034876  0.10424329]\n",
      " [0.08897529 0.11128447 0.10459483 0.11184528 0.10455728 0.09686876\n",
      "  0.098013   0.09099428 0.07958671 0.11328007]\n",
      " [0.08254254 0.12079658 0.09248928 0.1210482  0.12861525 0.08298101\n",
      "  0.0971188  0.08855201 0.08840383 0.09745245]\n",
      " [0.10975337 0.10260418 0.10466614 0.09570982 0.09881245 0.10661806\n",
      "  0.10186318 0.09008949 0.09200294 0.09788033]\n",
      " [0.09378859 0.10470292 0.09853267 0.11753371 0.10284956 0.10155482\n",
      "  0.11115798 0.09273246 0.08651762 0.09062973]\n",
      " [0.08792535 0.08692977 0.10903163 0.11134367 0.10299175 0.10867924\n",
      "  0.11137682 0.09653885 0.08572981 0.09945316]\n",
      " [0.08685043 0.11146509 0.09858962 0.09946758 0.10535196 0.11554307\n",
      "  0.09731973 0.0910315  0.09383357 0.10054741]\n",
      " [0.10248581 0.11238682 0.09608448 0.10920783 0.09945305 0.09687135\n",
      "  0.10473717 0.08413626 0.09142727 0.10320996]\n",
      " [0.10352217 0.11350301 0.10465421 0.09687155 0.09632686 0.10565694\n",
      "  0.09786989 0.09500784 0.0938786  0.09270903]\n",
      " [0.09153273 0.11542475 0.10074722 0.1196673  0.11219411 0.08863305\n",
      "  0.09686095 0.08620232 0.09089764 0.09783985]\n",
      " [0.09112946 0.10143366 0.10991353 0.11342852 0.10367095 0.10303777\n",
      "  0.09766458 0.0923458  0.0890266  0.09834913]\n",
      " [0.08396486 0.1278658  0.11063858 0.10963368 0.09762778 0.09560271\n",
      "  0.11693136 0.08324662 0.0887868  0.08570177]\n",
      " [0.08010815 0.1100171  0.0947696  0.09836136 0.11358674 0.10271155\n",
      "  0.09946384 0.09853479 0.0998964  0.10255038]\n",
      " [0.1002201  0.12115536 0.10424282 0.10174181 0.11449502 0.08875922\n",
      "  0.09514807 0.09627143 0.0816641  0.09630203]\n",
      " [0.09582212 0.11287521 0.09826931 0.11121256 0.09243542 0.09223443\n",
      "  0.10076898 0.11349045 0.07949502 0.10339647]\n",
      " [0.08938036 0.10733078 0.0944175  0.12664738 0.10507023 0.09791936\n",
      "  0.1096362  0.09296209 0.0850201  0.09161596]\n",
      " [0.10139012 0.11377597 0.11731182 0.10709409 0.08625027 0.0961806\n",
      "  0.10534315 0.09627311 0.08231074 0.09407009]\n",
      " [0.08495004 0.11547753 0.09052069 0.12485825 0.1015887  0.10028471\n",
      "  0.11390706 0.08078659 0.09031256 0.09731394]\n",
      " [0.0906966  0.09594353 0.09228776 0.11222064 0.10336486 0.11913791\n",
      "  0.10363787 0.08955717 0.08348281 0.10967093]\n",
      " [0.10221539 0.11133778 0.11771072 0.09599928 0.10832509 0.09494633\n",
      "  0.09118827 0.0904737  0.08978171 0.09802171]\n",
      " [0.0936282  0.10609675 0.09322625 0.11227809 0.101514   0.1003807\n",
      "  0.11595167 0.09095101 0.08743766 0.09853569]\n",
      " [0.09430411 0.10702934 0.10882141 0.1001028  0.11709195 0.08963704\n",
      "  0.10214569 0.09768968 0.08356149 0.09961648]\n",
      " [0.09784664 0.10355198 0.10266736 0.11808671 0.10360195 0.09919441\n",
      "  0.0937298  0.08763514 0.09204502 0.10164095]\n",
      " [0.08360559 0.10496967 0.10060547 0.10776884 0.11795113 0.09722517\n",
      "  0.10192267 0.09478378 0.09539107 0.09577668]\n",
      " [0.08687045 0.10934061 0.09537975 0.11077943 0.10789892 0.10144413\n",
      "  0.10505141 0.0871054  0.09558653 0.10054328]\n",
      " [0.09629949 0.09506412 0.10622221 0.11927959 0.10259528 0.09945685\n",
      "  0.10917039 0.0893978  0.08272635 0.09978791]\n",
      " [0.09300508 0.10379304 0.10983971 0.09986537 0.09035069 0.10589555\n",
      "  0.10703085 0.09488151 0.09207944 0.10325882]\n",
      " [0.09180842 0.09876584 0.10469673 0.11443099 0.11290246 0.10251368\n",
      "  0.09840271 0.09163307 0.09063943 0.09420671]\n",
      " [0.09702787 0.09322888 0.09532943 0.10702165 0.11056492 0.10525564\n",
      "  0.10247116 0.10215264 0.08481892 0.10212884]\n",
      " [0.08822491 0.1136983  0.1206285  0.09389569 0.09833651 0.11327112\n",
      "  0.09309348 0.10479614 0.07413158 0.09992383]\n",
      " [0.11021435 0.10979362 0.09930539 0.11888699 0.10956696 0.09309343\n",
      "  0.10234242 0.07853943 0.09356155 0.08469588]\n",
      " [0.09098431 0.10617926 0.08193386 0.12039881 0.1065172  0.09708682\n",
      "  0.10604621 0.09203209 0.09162841 0.10719303]\n",
      " [0.07991347 0.09447064 0.09280096 0.1045448  0.13073793 0.09154905\n",
      "  0.12248658 0.0836321  0.09757788 0.10228665]\n",
      " [0.08811887 0.09968641 0.11276444 0.10887972 0.10219146 0.09955078\n",
      "  0.10099521 0.09449193 0.08711158 0.10620961]\n",
      " [0.10248443 0.11427951 0.09383803 0.12044551 0.09584954 0.10071173\n",
      "  0.10145909 0.08443622 0.08396171 0.10253422]\n",
      " [0.08956137 0.11041061 0.10815703 0.10208922 0.09572967 0.11248457\n",
      "  0.11253764 0.09052145 0.08680158 0.09170695]\n",
      " [0.086091   0.10030455 0.11594202 0.10206265 0.10516859 0.10468866\n",
      "  0.10262254 0.08885709 0.09733343 0.09692954]\n",
      " [0.08771887 0.10495213 0.10930333 0.10952636 0.09589005 0.11313564\n",
      "  0.09589114 0.08736528 0.08642978 0.10978746]\n",
      " [0.09801838 0.10162479 0.1045314  0.10191434 0.1061869  0.10264859\n",
      "  0.10805032 0.09111091 0.08527412 0.10064027]\n",
      " [0.09950696 0.10128932 0.08962015 0.11769721 0.10753474 0.09552476\n",
      "  0.10159831 0.09090989 0.10536423 0.09095444]\n",
      " [0.09759216 0.10540722 0.10000638 0.10627289 0.11142157 0.09374734\n",
      "  0.1024     0.08659206 0.10891886 0.08764155]\n",
      " [0.09343907 0.10560729 0.09734242 0.11282244 0.11456084 0.08605338\n",
      "  0.11824114 0.09303826 0.10011867 0.07877654]\n",
      " [0.11031561 0.10507768 0.11071441 0.10740069 0.08919609 0.09951404\n",
      "  0.12521607 0.07183024 0.0876364  0.09309879]\n",
      " [0.11410588 0.11033528 0.094169   0.10972979 0.09956706 0.09854769\n",
      "  0.10783622 0.08970795 0.08534985 0.09065136]\n",
      " [0.11071414 0.11972015 0.09394652 0.09921817 0.09942438 0.08566642\n",
      "  0.11428087 0.08845766 0.09645563 0.09211607]\n",
      " [0.08227591 0.09805236 0.10167963 0.10768786 0.10669247 0.09625313\n",
      "  0.11014862 0.10936437 0.08564684 0.10219876]\n",
      " [0.09267914 0.10983827 0.09809824 0.09467938 0.11300462 0.10148257\n",
      "  0.10910193 0.09306549 0.08738505 0.10066532]\n",
      " [0.09959984 0.10961708 0.10426382 0.10947839 0.10034404 0.09484848\n",
      "  0.09882996 0.10443707 0.08939753 0.08918379]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.30859, step = 1\n",
      "INFO:tensorflow:probabilities = [[0.0800093  0.09669501 0.09314363 0.11618143 0.1142557  0.10787055\n",
      "  0.09968249 0.0916408  0.10556092 0.09496018]\n",
      " [0.09752642 0.09559543 0.09971312 0.11149945 0.11397073 0.10281788\n",
      "  0.09344251 0.09601455 0.09456264 0.0948572 ]\n",
      " [0.08261061 0.10331064 0.12264408 0.12610328 0.10591568 0.10462619\n",
      "  0.09226826 0.08122808 0.08875089 0.0925423 ]\n",
      " [0.1003589  0.11114069 0.09530546 0.11634029 0.101218   0.0985846\n",
      "  0.10510015 0.08923098 0.08936372 0.09335715]\n",
      " [0.0991965  0.12135587 0.10865832 0.1017021  0.09372654 0.10429733\n",
      "  0.10262302 0.09462241 0.08398445 0.08983346]\n",
      " [0.09495046 0.09533456 0.09964896 0.10582875 0.1031106  0.10569786\n",
      "  0.09480913 0.09759872 0.09821543 0.10480545]\n",
      " [0.09358569 0.09955294 0.09992743 0.11952845 0.11157995 0.09256958\n",
      "  0.11334158 0.08520522 0.0830469  0.10166218]\n",
      " [0.09922774 0.10104702 0.10698095 0.11119199 0.10465815 0.09341113\n",
      "  0.10095188 0.09288399 0.09015589 0.09949131]\n",
      " [0.09486963 0.11006027 0.10129055 0.10414772 0.08914642 0.10388478\n",
      "  0.10785222 0.0832117  0.09915002 0.10638665]\n",
      " [0.09875127 0.10287182 0.10272704 0.10591525 0.1013514  0.09954473\n",
      "  0.09829333 0.0966319  0.09431397 0.09959935]\n",
      " [0.10014869 0.10559553 0.09596649 0.10273327 0.09743845 0.10838969\n",
      "  0.09552198 0.0996427  0.08351857 0.11104456]\n",
      " [0.11605888 0.10069885 0.11788568 0.09701565 0.09218144 0.10195986\n",
      "  0.09935639 0.09125996 0.08781175 0.09577153]\n",
      " [0.09721328 0.09613609 0.10215371 0.10747616 0.0953684  0.10035995\n",
      "  0.10357693 0.09197322 0.10112505 0.10461727]\n",
      " [0.11159771 0.10624004 0.10732683 0.1035059  0.10381484 0.10397995\n",
      "  0.0957359  0.08725479 0.09318279 0.08736119]\n",
      " [0.0983514  0.09967121 0.10155808 0.11010721 0.10138895 0.10603846\n",
      "  0.09776807 0.09582902 0.0918737  0.09741383]\n",
      " [0.09283058 0.10345579 0.10079676 0.10385543 0.10792907 0.08988959\n",
      "  0.0970751  0.10040253 0.10757265 0.09619248]\n",
      " [0.0972427  0.10275385 0.09952822 0.10569587 0.10999907 0.10066533\n",
      "  0.09709045 0.0954014  0.10136992 0.09025329]\n",
      " [0.09604844 0.10981112 0.11256424 0.11157852 0.09689201 0.10023647\n",
      "  0.10435401 0.08986479 0.08567448 0.09297593]\n",
      " [0.09272795 0.10189029 0.11173934 0.09473386 0.11015864 0.1034862\n",
      "  0.11297137 0.09611417 0.07674308 0.09943505]\n",
      " [0.1016401  0.09511695 0.10327004 0.1235282  0.12176284 0.09487441\n",
      "  0.10478202 0.08533686 0.08705443 0.08263411]\n",
      " [0.09647269 0.09432217 0.10551784 0.10395818 0.10320375 0.09861768\n",
      "  0.10787424 0.10009572 0.0951662  0.09477156]\n",
      " [0.09199815 0.09629827 0.09780479 0.11256665 0.09800048 0.11962977\n",
      "  0.10025621 0.10679149 0.07983859 0.09681558]\n",
      " [0.08584046 0.10195071 0.09124812 0.10497513 0.11586689 0.10403928\n",
      "  0.11436058 0.09464426 0.09166892 0.09540574]\n",
      " [0.08816323 0.11229268 0.10230147 0.10087729 0.10315395 0.10765391\n",
      "  0.09661138 0.09571595 0.09837425 0.09485593]\n",
      " [0.09674443 0.10135222 0.1005564  0.10943788 0.10158423 0.09955152\n",
      "  0.10224966 0.0998674  0.09574776 0.09290853]\n",
      " [0.08824092 0.09767035 0.09895467 0.10686808 0.10571561 0.09941173\n",
      "  0.10294657 0.09929593 0.09914482 0.1017514 ]\n",
      " [0.09371199 0.10281424 0.09157746 0.11849897 0.1205804  0.09610961\n",
      "  0.10055342 0.09374312 0.0828114  0.09959936]\n",
      " [0.09540763 0.10764561 0.09688757 0.11388526 0.10903837 0.09951187\n",
      "  0.09465674 0.09414433 0.09104495 0.09777768]\n",
      " [0.0890358  0.11138777 0.10167762 0.10732888 0.11783227 0.10251489\n",
      "  0.09559698 0.10118929 0.08726404 0.08617244]\n",
      " [0.09675441 0.10852648 0.11702949 0.10539615 0.1075792  0.09831461\n",
      "  0.10415216 0.08410782 0.0809598  0.09717992]\n",
      " [0.10891058 0.09414022 0.10344919 0.10776471 0.09963531 0.07807746\n",
      "  0.1090036  0.09720271 0.0938501  0.10796611]\n",
      " [0.10047381 0.10272201 0.09448159 0.10880975 0.10920445 0.10331763\n",
      "  0.109877   0.09076076 0.08058771 0.09976522]\n",
      " [0.0998795  0.10607462 0.08954845 0.11006274 0.10723533 0.09647727\n",
      "  0.09727091 0.10362387 0.10103451 0.08879277]\n",
      " [0.09690905 0.09869891 0.10817649 0.1024529  0.09986953 0.0881977\n",
      "  0.11106776 0.10928514 0.09003344 0.0953091 ]\n",
      " [0.0944648  0.09733649 0.09397197 0.12073912 0.1116185  0.10979477\n",
      "  0.09768625 0.08159527 0.09491865 0.09787421]\n",
      " [0.088899   0.0998467  0.10385081 0.10847467 0.09338149 0.1015813\n",
      "  0.10770185 0.09508199 0.09165558 0.1095266 ]\n",
      " [0.09504344 0.12135594 0.11124494 0.10286814 0.10879655 0.09772383\n",
      "  0.10843594 0.08169638 0.08564467 0.08719012]\n",
      " [0.0874709  0.11191303 0.10215899 0.12111808 0.09781877 0.1003505\n",
      "  0.09297957 0.09265062 0.08701396 0.10652559]\n",
      " [0.10137583 0.10075203 0.09838047 0.12184547 0.09351286 0.09961692\n",
      "  0.10206595 0.10254905 0.08741803 0.09248336]\n",
      " [0.10495174 0.11239716 0.10227745 0.10583778 0.10277502 0.08972623\n",
      "  0.10195556 0.09463033 0.09023435 0.09521439]\n",
      " [0.09585217 0.11444174 0.10001324 0.11404652 0.11260893 0.09455302\n",
      "  0.10432311 0.08537661 0.09714349 0.08164117]\n",
      " [0.09062967 0.10234388 0.09585693 0.10698792 0.10261688 0.10005876\n",
      "  0.09987435 0.10081273 0.10146724 0.09935167]\n",
      " [0.10222931 0.10433707 0.10585695 0.10115351 0.09183813 0.10408624\n",
      "  0.08803663 0.11205546 0.10530143 0.0851053 ]\n",
      " [0.08475471 0.10449017 0.09724933 0.10533354 0.11350805 0.09888163\n",
      "  0.10034413 0.09688069 0.09740168 0.10115606]\n",
      " [0.10993808 0.10150042 0.10305579 0.10596918 0.10081215 0.09814727\n",
      "  0.10442325 0.09347915 0.0810882  0.10158643]\n",
      " [0.10052676 0.09484551 0.10507922 0.11422157 0.10247709 0.10150281\n",
      "  0.10369428 0.0873256  0.09539659 0.09493057]\n",
      " [0.09175657 0.10222312 0.10210811 0.10740186 0.10306599 0.10427034\n",
      "  0.09945116 0.10510702 0.09577378 0.08884206]\n",
      " [0.09696069 0.10253128 0.11087487 0.10412197 0.09569822 0.10211063\n",
      "  0.1029595  0.09496084 0.09188898 0.09789307]\n",
      " [0.0911686  0.129995   0.09915923 0.11992536 0.09359433 0.09145594\n",
      "  0.10386063 0.0900773  0.08288303 0.09788049]\n",
      " [0.09955029 0.10039397 0.10405685 0.10856411 0.09723935 0.0920407\n",
      "  0.10163473 0.10241707 0.09409393 0.10000899]\n",
      " [0.09140741 0.1082025  0.10048459 0.11616321 0.09987853 0.09409849\n",
      "  0.10461407 0.09519857 0.09543242 0.09452026]\n",
      " [0.08796426 0.10281885 0.09024519 0.12392221 0.11179911 0.09274935\n",
      "  0.10814306 0.09912432 0.09394138 0.08929228]\n",
      " [0.09507461 0.10802162 0.11408798 0.11157842 0.09860715 0.09597889\n",
      "  0.10543457 0.08067279 0.08639386 0.10415011]\n",
      " [0.09845065 0.10451938 0.11004486 0.10275114 0.0949556  0.1093649\n",
      "  0.10752975 0.08927757 0.08304321 0.10006288]\n",
      " [0.09424391 0.10160291 0.0938045  0.11378361 0.10154933 0.11453155\n",
      "  0.08887671 0.0919269  0.09565222 0.10402834]\n",
      " [0.08546273 0.11589814 0.09576451 0.11330675 0.1104518  0.09163079\n",
      "  0.10364107 0.09194285 0.08116312 0.1107382 ]\n",
      " [0.0994693  0.0987358  0.10303334 0.11236897 0.09392273 0.09970761\n",
      "  0.10075056 0.1017089  0.08903927 0.10126353]\n",
      " [0.10447674 0.10184259 0.09473356 0.11339986 0.1187747  0.08922218\n",
      "  0.10982319 0.07502363 0.09984997 0.09285358]\n",
      " [0.09148131 0.10183363 0.10045856 0.10169936 0.11436056 0.09127274\n",
      "  0.10293386 0.0937443  0.09831024 0.10390545]\n",
      " [0.09453833 0.10203653 0.11606646 0.10342954 0.10337008 0.10928614\n",
      "  0.1020179  0.0908222  0.0847315  0.09370133]\n",
      " [0.09316424 0.11464419 0.097142   0.11109082 0.09899334 0.09197158\n",
      "  0.10129517 0.10090119 0.09306845 0.09772903]\n",
      " [0.09046283 0.10619827 0.09911309 0.11410912 0.0910966  0.11869905\n",
      "  0.09999682 0.09445086 0.09130396 0.09456936]\n",
      " [0.09532923 0.09775604 0.09854867 0.10487602 0.10192627 0.09938657\n",
      "  0.10466664 0.10383456 0.10073229 0.09294377]\n",
      " [0.09330527 0.10741037 0.0960616  0.1076426  0.09418911 0.09944972\n",
      "  0.10481515 0.10259498 0.08582    0.10871123]\n",
      " [0.10110316 0.108697   0.1014468  0.1051485  0.10057557 0.10594796\n",
      "  0.09647126 0.09278549 0.09568088 0.09214336]\n",
      " [0.10239437 0.09485638 0.1304208  0.09568008 0.10860125 0.10231674\n",
      "  0.09748707 0.08704972 0.08349001 0.09770358]\n",
      " [0.09946909 0.10245273 0.09834608 0.12307302 0.11706188 0.09384011\n",
      "  0.11912979 0.08493247 0.07446761 0.08722725]\n",
      " [0.09329806 0.09619008 0.11078382 0.1147772  0.08998849 0.11544044\n",
      "  0.0937895  0.09198545 0.09731417 0.09643277]\n",
      " [0.112276   0.10092523 0.09303531 0.1020575  0.09988824 0.09293488\n",
      "  0.10958733 0.09428737 0.10443234 0.09057583]\n",
      " [0.10583246 0.12180643 0.1221529  0.08931924 0.09863741 0.08845641\n",
      "  0.12023748 0.07971174 0.08089051 0.0929555 ]\n",
      " [0.09126522 0.10200077 0.09952027 0.09917559 0.11451567 0.09787948\n",
      "  0.10540455 0.09232819 0.08343173 0.11447852]\n",
      " [0.09021942 0.1101793  0.10042912 0.10367581 0.11124807 0.09282365\n",
      "  0.11672532 0.08530473 0.08737765 0.1020169 ]\n",
      " [0.08194321 0.10038962 0.10240909 0.10345193 0.11818536 0.09169117\n",
      "  0.09225044 0.09304544 0.09931894 0.11731476]\n",
      " [0.09710302 0.10614476 0.11249961 0.10747787 0.09767894 0.0999191\n",
      "  0.09702781 0.11185002 0.08644946 0.0838494 ]\n",
      " [0.08341124 0.09637961 0.10216316 0.11025008 0.09885295 0.10331839\n",
      "  0.11010214 0.09100618 0.0959981  0.10851825]\n",
      " [0.11913931 0.09807278 0.10423648 0.09526454 0.11093751 0.09977983\n",
      "  0.10725362 0.08298631 0.09264056 0.08968914]\n",
      " [0.0988564  0.10504697 0.09162222 0.10883844 0.09981263 0.10279595\n",
      "  0.1078089  0.08689776 0.1039067  0.09441403]\n",
      " [0.10182653 0.09309334 0.1141607  0.10838731 0.10254485 0.0941128\n",
      "  0.09034811 0.09572537 0.09339017 0.10641081]\n",
      " [0.08651732 0.10018922 0.10449364 0.11371871 0.10303727 0.09300099\n",
      "  0.10920078 0.10020465 0.08351782 0.10611966]\n",
      " [0.09733585 0.09735619 0.08937611 0.12183417 0.1052549  0.09954493\n",
      "  0.10649178 0.1068703  0.09370977 0.08222597]\n",
      " [0.08947572 0.11863561 0.10036077 0.10168444 0.11042117 0.09550373\n",
      "  0.09823161 0.09476183 0.09031832 0.10060675]\n",
      " [0.092656   0.10338973 0.08389463 0.11682014 0.10611901 0.09844188\n",
      "  0.1210994  0.10231512 0.09217387 0.08309018]\n",
      " [0.09759646 0.10245307 0.10644542 0.11023305 0.10390901 0.10491914\n",
      "  0.10078885 0.08909602 0.09292615 0.0916329 ]\n",
      " [0.10305121 0.10357832 0.08485743 0.11198431 0.09955705 0.09521111\n",
      "  0.11275224 0.09936933 0.09316394 0.09647515]\n",
      " [0.08859377 0.10309625 0.096774   0.11631237 0.10127755 0.11074749\n",
      "  0.09521951 0.1021738  0.08996121 0.09584411]\n",
      " [0.08629887 0.10581951 0.09718047 0.12060983 0.1169919  0.10131975\n",
      "  0.09653214 0.09543921 0.09042997 0.08937833]\n",
      " [0.11273943 0.10583355 0.09507111 0.10822283 0.10943986 0.09383298\n",
      "  0.1053331  0.09337386 0.08024141 0.09591187]\n",
      " [0.09258743 0.09856226 0.10949536 0.1112055  0.10958431 0.10037008\n",
      "  0.09641722 0.09690729 0.09778367 0.08708689]\n",
      " [0.09034751 0.13092679 0.0987866  0.0960449  0.11324836 0.09835581\n",
      "  0.09545475 0.09320003 0.08593576 0.09769944]\n",
      " [0.10458243 0.09382901 0.10520897 0.11010122 0.10246088 0.08776408\n",
      "  0.10745391 0.093999   0.10307441 0.09152602]\n",
      " [0.09465621 0.11114137 0.08768303 0.10229298 0.11101194 0.10487222\n",
      "  0.09460198 0.10515343 0.08890256 0.09968433]\n",
      " [0.10484775 0.10600788 0.10168099 0.11294591 0.09189042 0.0957128\n",
      "  0.09453623 0.09019785 0.09489279 0.1072874 ]\n",
      " [0.10183915 0.10963118 0.10794006 0.11399222 0.09553487 0.09532878\n",
      "  0.08626514 0.09315402 0.09350197 0.10281257]\n",
      " [0.0951225  0.09560669 0.10463971 0.11284842 0.09191495 0.08988285\n",
      "  0.097637   0.10209768 0.10077304 0.10947706]\n",
      " [0.09553344 0.11118675 0.10626449 0.10545014 0.1023947  0.09021153\n",
      "  0.10267286 0.09785126 0.09416457 0.09427023]\n",
      " [0.10258069 0.1159329  0.10783429 0.11355161 0.09875914 0.08956472\n",
      "  0.10708802 0.09494127 0.08072542 0.08902201]\n",
      " [0.10809357 0.11002973 0.10461479 0.09560917 0.09963787 0.1029219\n",
      "  0.10650571 0.08295269 0.09340682 0.09622777]\n",
      " [0.09500179 0.10594145 0.10376458 0.10560942 0.10832428 0.07700834\n",
      "  0.12327492 0.08919352 0.08876795 0.10311376]\n",
      " [0.09708174 0.10256293 0.1085386  0.10910045 0.10830534 0.10169861\n",
      "  0.09739278 0.09829727 0.08728379 0.08973852]\n",
      " [0.10268042 0.11644451 0.10844985 0.10006414 0.10815435 0.08799287\n",
      "  0.09227344 0.09291153 0.0957015  0.09532735]] (12.892 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.952\n",
      "INFO:tensorflow:probabilities = [[0.09879071 0.10468376 0.10238783 0.10299674 0.11938692 0.09047454\n",
      "  0.09642135 0.09472219 0.10168677 0.08844922]\n",
      " [0.09752667 0.10031038 0.12101587 0.10791812 0.09219404 0.11182535\n",
      "  0.07563887 0.09303723 0.09832101 0.10221248]\n",
      " [0.09656877 0.10789663 0.09913815 0.12645318 0.08773687 0.09050149\n",
      "  0.10874797 0.0816637  0.08909393 0.11219937]\n",
      " [0.10178983 0.09650122 0.11250165 0.09540424 0.09968642 0.11099612\n",
      "  0.10839473 0.09014298 0.09372442 0.09085841]\n",
      " [0.0954382  0.10883226 0.10378562 0.11559903 0.09968332 0.10000307\n",
      "  0.10121059 0.09756123 0.08615799 0.09172866]\n",
      " [0.10995241 0.09818623 0.10747418 0.10052004 0.0973435  0.08756413\n",
      "  0.11089188 0.09592519 0.09461712 0.09752529]\n",
      " [0.10071743 0.09561583 0.10993101 0.1097069  0.09375365 0.11797709\n",
      "  0.09737667 0.09487616 0.08247936 0.09756593]\n",
      " [0.09612709 0.09595086 0.10723211 0.09317271 0.09432139 0.11362825\n",
      "  0.10329439 0.09186922 0.08832072 0.11608317]\n",
      " [0.0929134  0.08928174 0.10064021 0.11274365 0.10993209 0.10508543\n",
      "  0.09829798 0.09408641 0.09829797 0.09872113]\n",
      " [0.10788107 0.09094681 0.10080387 0.1269689  0.09791477 0.09619688\n",
      "  0.10981044 0.07994778 0.08611406 0.10341537]\n",
      " [0.08388843 0.10048556 0.09512445 0.10129956 0.10791913 0.09554747\n",
      "  0.10316712 0.09980681 0.11248189 0.10027954]\n",
      " [0.0901125  0.10471563 0.09738541 0.10348652 0.1083556  0.10234088\n",
      "  0.09781402 0.09665614 0.09665541 0.10247789]\n",
      " [0.08329987 0.10418447 0.09321699 0.10379388 0.10446023 0.10378258\n",
      "  0.11843504 0.09725726 0.09001474 0.10155494]\n",
      " [0.10343368 0.09316385 0.10786078 0.10289464 0.10785107 0.0978548\n",
      "  0.10224528 0.09803509 0.08996034 0.09670045]\n",
      " [0.08942278 0.09383986 0.0963201  0.11910363 0.12379491 0.0902753\n",
      "  0.08804567 0.10258809 0.09574029 0.10086932]\n",
      " [0.09890193 0.09543842 0.11249298 0.10680422 0.09989616 0.09626125\n",
      "  0.12229398 0.09568001 0.08358046 0.08865047]\n",
      " [0.08396202 0.1132276  0.10936204 0.09717678 0.11234536 0.10001502\n",
      "  0.10019568 0.0884568  0.09021426 0.10504441]\n",
      " [0.11528245 0.09567434 0.12333699 0.09391493 0.10247902 0.1016751\n",
      "  0.09938949 0.08044212 0.08801131 0.09979438]\n",
      " [0.08143102 0.09446735 0.09956115 0.11993296 0.11340812 0.1155881\n",
      "  0.0930659  0.08885451 0.08747575 0.10621509]\n",
      " [0.09714688 0.09405701 0.11158589 0.09867603 0.12375575 0.09074777\n",
      "  0.09969329 0.09282667 0.08614397 0.10536666]\n",
      " [0.10848078 0.11618277 0.09741032 0.1083269  0.08664105 0.09977727\n",
      "  0.11088128 0.08973572 0.08663889 0.09592509]\n",
      " [0.09408588 0.09310902 0.11883804 0.11391358 0.1180243  0.09302106\n",
      "  0.09629419 0.08683293 0.08551591 0.10036508]\n",
      " [0.12160236 0.09061458 0.10263256 0.099207   0.09685811 0.09957191\n",
      "  0.10864998 0.09073286 0.0904767  0.09965394]\n",
      " [0.09565847 0.10044058 0.0950349  0.11569989 0.10355161 0.08571786\n",
      "  0.10716465 0.09909824 0.09833324 0.0993005 ]\n",
      " [0.11037967 0.0933604  0.12770298 0.10239366 0.09423722 0.09331624\n",
      "  0.10039042 0.08978845 0.09363275 0.0947981 ]\n",
      " [0.09651232 0.11172094 0.10074122 0.11128496 0.1169204  0.09558491\n",
      "  0.11131531 0.08242439 0.08056587 0.09292965]\n",
      " [0.08581963 0.10193707 0.1078871  0.10141785 0.10923529 0.09593935\n",
      "  0.10333662 0.09136134 0.09445109 0.10861471]\n",
      " [0.1096708  0.09140465 0.11494489 0.11425819 0.09347027 0.09616409\n",
      "  0.09913749 0.08906338 0.08670264 0.10518362]\n",
      " [0.10575102 0.09224238 0.10747068 0.11516325 0.10278424 0.08710793\n",
      "  0.10420088 0.0953668  0.08382822 0.10608464]\n",
      " [0.12203391 0.09936214 0.10379235 0.09843466 0.10585484 0.09779286\n",
      "  0.10098056 0.08304542 0.09342594 0.09527734]\n",
      " [0.10387276 0.09462596 0.09930595 0.12201137 0.09601729 0.1032156\n",
      "  0.10661414 0.08437993 0.09770368 0.09225324]\n",
      " [0.08843336 0.10596892 0.09645908 0.10938193 0.09503383 0.10306544\n",
      "  0.10299953 0.10528896 0.09464522 0.09872372]\n",
      " [0.08081063 0.11558716 0.10118257 0.11155365 0.10277373 0.09400537\n",
      "  0.11121976 0.09456428 0.0980347  0.09026804]\n",
      " [0.08903021 0.09273049 0.09892222 0.10563689 0.1146579  0.09747815\n",
      "  0.12088992 0.09516726 0.09507608 0.09041079]\n",
      " [0.08643807 0.10077864 0.09660736 0.10514586 0.10303166 0.1000826\n",
      "  0.10609908 0.1056544  0.10338838 0.09277397]\n",
      " [0.09015092 0.10686141 0.09373157 0.11913649 0.10780735 0.092075\n",
      "  0.10457281 0.09846545 0.09526155 0.09193747]\n",
      " [0.09422743 0.1021091  0.09348349 0.11556449 0.10500897 0.09324641\n",
      "  0.10274647 0.10055925 0.10237662 0.09067783]\n",
      " [0.10886374 0.10913251 0.09587675 0.10904544 0.09519199 0.09210849\n",
      "  0.1047447  0.08519699 0.0911203  0.10871904]\n",
      " [0.0877872  0.0916407  0.11095741 0.12626661 0.09469206 0.10248778\n",
      "  0.10262019 0.09078765 0.09537624 0.09738415]\n",
      " [0.10011178 0.09581072 0.10742553 0.11082605 0.11114672 0.09278525\n",
      "  0.10042498 0.10404979 0.07843701 0.09898219]\n",
      " [0.10654312 0.10524625 0.08894787 0.11013673 0.11363055 0.09875382\n",
      "  0.08439054 0.09258833 0.09415712 0.10560567]\n",
      " [0.08616003 0.10560054 0.10417069 0.10176415 0.11624354 0.10008334\n",
      "  0.1018033  0.09616203 0.08762109 0.10039133]\n",
      " [0.09854859 0.10023691 0.10635202 0.09699873 0.11882107 0.10891384\n",
      "  0.09962295 0.09807213 0.08598249 0.08645131]\n",
      " [0.0909962  0.10483287 0.11786862 0.10649614 0.12342932 0.09469234\n",
      "  0.10036019 0.08903775 0.09419776 0.07808889]\n",
      " [0.08446881 0.10206927 0.11455237 0.11358307 0.10709519 0.08769128\n",
      "  0.10570633 0.09836715 0.09649334 0.08997318]\n",
      " [0.08735343 0.10148786 0.1043606  0.12178847 0.10745688 0.09183139\n",
      "  0.10259695 0.10765053 0.07754709 0.09792678]\n",
      " [0.09494504 0.10174458 0.11819121 0.11258581 0.09611416 0.09448021\n",
      "  0.08681255 0.09886488 0.09033076 0.10593086]\n",
      " [0.09894206 0.09878926 0.10999389 0.11316954 0.09952921 0.08790003\n",
      "  0.09413623 0.10129471 0.08936106 0.106884  ]\n",
      " [0.0960051  0.08929078 0.10630164 0.11313988 0.09991663 0.09690773\n",
      "  0.10238046 0.09159037 0.0905688  0.11389863]\n",
      " [0.10018145 0.09223336 0.1047385  0.12032603 0.09939509 0.10172763\n",
      "  0.09922154 0.10042819 0.08721662 0.09453158]\n",
      " [0.09413418 0.10153563 0.11340131 0.10965188 0.10055053 0.09625681\n",
      "  0.093972   0.0955451  0.09730788 0.09764465]\n",
      " [0.10274535 0.08775013 0.11505905 0.11001559 0.10464829 0.09875826\n",
      "  0.10095877 0.08119808 0.09244259 0.10642388]\n",
      " [0.09192193 0.09938988 0.09374511 0.11496563 0.10532176 0.09106511\n",
      "  0.1020548  0.09998835 0.09580119 0.10574622]\n",
      " [0.08612273 0.10422299 0.09445591 0.11214148 0.10427286 0.09582901\n",
      "  0.10431852 0.095001   0.09733304 0.10630246]\n",
      " [0.10163132 0.11193147 0.11232314 0.10545565 0.09897751 0.10719553\n",
      "  0.10045046 0.09106016 0.08164752 0.08932729]\n",
      " [0.09342501 0.10171135 0.09856005 0.12484963 0.10166519 0.09146748\n",
      "  0.09876399 0.09524937 0.09246338 0.10184456]\n",
      " [0.08582587 0.10690574 0.11935491 0.10614917 0.09581303 0.09676109\n",
      "  0.12559612 0.08204669 0.08673581 0.09481152]\n",
      " [0.11486454 0.11160184 0.10821847 0.10151716 0.09426952 0.09968229\n",
      "  0.09458147 0.08090328 0.08450294 0.10985857]\n",
      " [0.10116586 0.10074644 0.09994914 0.11771823 0.10745532 0.09095906\n",
      "  0.10194775 0.09009126 0.1000623  0.0899047 ]\n",
      " [0.10148752 0.09978491 0.09911148 0.10210861 0.10187455 0.09546256\n",
      "  0.11645015 0.09731785 0.09423535 0.09216702]\n",
      " [0.0899785  0.10816097 0.10360639 0.11109377 0.10331618 0.10596489\n",
      "  0.10932565 0.07846911 0.08824698 0.10183758]\n",
      " [0.09696037 0.10236114 0.09808985 0.12207659 0.09177265 0.09927896\n",
      "  0.10060381 0.09903291 0.08948037 0.10034333]\n",
      " [0.11237093 0.09464739 0.11566921 0.10406714 0.09917837 0.08652654\n",
      "  0.10078165 0.0916997  0.09116013 0.10389893]\n",
      " [0.10183238 0.11277981 0.11840565 0.10287588 0.09475558 0.09935728\n",
      "  0.09438594 0.08599198 0.09034007 0.09927551]\n",
      " [0.11280495 0.11351238 0.09882195 0.11384638 0.10373137 0.09232701\n",
      "  0.09495714 0.09056621 0.09195199 0.08748065]\n",
      " [0.10402812 0.11587741 0.09080447 0.1138783  0.10132651 0.09346732\n",
      "  0.10580054 0.09558067 0.09095417 0.08828243]\n",
      " [0.10085491 0.10024235 0.10799567 0.1128151  0.09619701 0.09901518\n",
      "  0.11088604 0.09522713 0.09229115 0.0844755 ]\n",
      " [0.09871221 0.10223004 0.10494882 0.11017273 0.09459581 0.1031959\n",
      "  0.09889521 0.09788917 0.09114352 0.09821655]\n",
      " [0.12220518 0.11106288 0.11346702 0.09465781 0.09902042 0.09126407\n",
      "  0.11052753 0.08699909 0.07731045 0.09348561]\n",
      " [0.09593709 0.08626003 0.10759831 0.12327008 0.09833241 0.09535632\n",
      "  0.11059342 0.10227463 0.08179151 0.09858617]\n",
      " [0.10477661 0.09390876 0.10387748 0.12447633 0.09598617 0.10097873\n",
      "  0.09432516 0.09297197 0.09851659 0.09018223]\n",
      " [0.09592818 0.09201773 0.10222847 0.1137121  0.11568434 0.10638218\n",
      "  0.09417678 0.10155948 0.08071869 0.09759201]\n",
      " [0.08926574 0.0965284  0.08756571 0.10472262 0.12078368 0.09661096\n",
      "  0.10298049 0.09704844 0.1025283  0.10196578]\n",
      " [0.08984356 0.09484521 0.09418571 0.10667386 0.11100087 0.10063604\n",
      "  0.10010543 0.09652519 0.10474543 0.10143869]\n",
      " [0.09489785 0.08545753 0.12139251 0.11038807 0.09241758 0.1183143\n",
      "  0.09167942 0.08664865 0.09963371 0.09917036]\n",
      " [0.11061551 0.11137614 0.10801611 0.10043964 0.10892672 0.08330455\n",
      "  0.10990913 0.08245386 0.09033646 0.09462198]\n",
      " [0.10401439 0.10130164 0.10351648 0.11729415 0.10359664 0.08794113\n",
      "  0.09565527 0.0970808  0.09439934 0.09520011]\n",
      " [0.10216768 0.09742298 0.11794466 0.09554251 0.09961237 0.0926616\n",
      "  0.10224102 0.09179745 0.09463493 0.10597476]\n",
      " [0.08843669 0.09853154 0.11049444 0.09690952 0.10663362 0.09888015\n",
      "  0.10010804 0.09577782 0.10960509 0.09462308]\n",
      " [0.11913482 0.1102075  0.09518897 0.1011133  0.10689691 0.09585677\n",
      "  0.10710634 0.0798476  0.08385349 0.10079424]\n",
      " [0.1079232  0.1130141  0.11149359 0.09771848 0.09190463 0.10009261\n",
      "  0.11026303 0.09169685 0.08601131 0.08988222]\n",
      " [0.09907115 0.09316707 0.09734706 0.11008224 0.10220494 0.10414564\n",
      "  0.09946747 0.0874043  0.0960324  0.11107772]\n",
      " [0.08545744 0.10553262 0.10197558 0.11772428 0.10310379 0.0895321\n",
      "  0.09726798 0.09590681 0.10418396 0.09931547]\n",
      " [0.10787251 0.10261147 0.1066561  0.10508378 0.10224956 0.09688965\n",
      "  0.10386808 0.09861422 0.08055364 0.09560099]\n",
      " [0.11644939 0.10052269 0.09893435 0.10017889 0.09697567 0.08516409\n",
      "  0.11181667 0.10003999 0.09148214 0.09843617]\n",
      " [0.0923849  0.10063905 0.10864387 0.1061901  0.10240553 0.11134358\n",
      "  0.10155389 0.09020692 0.08994505 0.09668712]\n",
      " [0.09379517 0.10120992 0.10930625 0.10723367 0.10251217 0.10525221\n",
      "  0.09278755 0.0966242  0.101277   0.09000191]\n",
      " [0.10089108 0.11324234 0.11963026 0.09723657 0.10739566 0.09857237\n",
      "  0.09461854 0.09060323 0.08801952 0.08979037]\n",
      " [0.10663989 0.10233002 0.0949396  0.10483263 0.09642992 0.10248805\n",
      "  0.10599949 0.09538791 0.10116646 0.08978596]\n",
      " [0.0998798  0.10082234 0.10387911 0.10561151 0.11506633 0.10264215\n",
      "  0.09570711 0.09498077 0.08915678 0.09225401]\n",
      " [0.09257109 0.10203929 0.09414772 0.12315185 0.09507523 0.1019007\n",
      "  0.09918328 0.10017974 0.09577746 0.09597363]\n",
      " [0.09938277 0.09682422 0.10575384 0.12011389 0.11682141 0.08591255\n",
      "  0.09880053 0.08707697 0.09218022 0.09713366]\n",
      " [0.08217457 0.1185428  0.09617303 0.10858482 0.09874464 0.09527864\n",
      "  0.1018586  0.09095527 0.10727166 0.10041594]\n",
      " [0.08884588 0.10059055 0.09373995 0.1098197  0.10492873 0.09899781\n",
      "  0.09915522 0.10272824 0.10163875 0.09955519]\n",
      " [0.09918845 0.09901319 0.10386942 0.10912132 0.10212608 0.09790198\n",
      "  0.09516365 0.09814907 0.09451528 0.10095156]\n",
      " [0.11318548 0.10562132 0.09781353 0.11075556 0.09839477 0.09857182\n",
      "  0.09158064 0.10312387 0.08037374 0.10057925]\n",
      " [0.0862674  0.09844961 0.1113604  0.11888032 0.11073361 0.08780245\n",
      "  0.10270806 0.09550673 0.08889206 0.09939937]\n",
      " [0.10163853 0.09681823 0.11550675 0.10910667 0.0916085  0.10101055\n",
      "  0.11603003 0.08366983 0.07926913 0.10534179]\n",
      " [0.1004503  0.10307875 0.103807   0.1010235  0.09796213 0.08967442\n",
      "  0.11935058 0.08939075 0.09845589 0.0968067 ]\n",
      " [0.09981555 0.11320776 0.10862868 0.1072114  0.10499937 0.08914852\n",
      "  0.08837192 0.0966753  0.09501908 0.09692242]] (12.413 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.296753, step = 101 (25.309 sec)\n",
      "INFO:tensorflow:probabilities = [[0.10992286 0.09550392 0.1146547  0.11508106 0.0939092  0.092752\n",
      "  0.10751397 0.09099011 0.08894873 0.09072343]\n",
      " [0.09262954 0.08447839 0.10823274 0.11024371 0.10290331 0.10276479\n",
      "  0.09465692 0.1084476  0.10395571 0.0916872 ]\n",
      " [0.0855128  0.09756333 0.09280218 0.11526673 0.11115606 0.09026374\n",
      "  0.12036441 0.09243825 0.09640814 0.09822432]\n",
      " [0.11348408 0.08200869 0.10596502 0.11453378 0.08786602 0.09863001\n",
      "  0.093342   0.10204393 0.09884266 0.10328379]\n",
      " [0.0955034  0.10291666 0.10007298 0.11801534 0.09225517 0.09759955\n",
      "  0.09561348 0.10372664 0.10228559 0.09201115]\n",
      " [0.09647299 0.10105363 0.10082173 0.11255173 0.09381627 0.09657843\n",
      "  0.11248669 0.08889095 0.09680102 0.10052659]\n",
      " [0.10062213 0.10008728 0.09730937 0.09724372 0.10140554 0.11570864\n",
      "  0.09363776 0.10433956 0.09730984 0.09233621]\n",
      " [0.10465526 0.11145733 0.10446771 0.10561836 0.10620908 0.09070127\n",
      "  0.10077164 0.10474015 0.08612397 0.0852552 ]\n",
      " [0.10090397 0.09253229 0.10782548 0.11056919 0.10696398 0.10261535\n",
      "  0.09317433 0.10481603 0.08933849 0.09126085]\n",
      " [0.11895987 0.10191725 0.11265093 0.11147509 0.10581358 0.09334535\n",
      "  0.09957067 0.07993987 0.07974748 0.09657996]\n",
      " [0.08653137 0.10585275 0.09279538 0.10540205 0.10996378 0.10456814\n",
      "  0.09715568 0.09882271 0.1021603  0.09674779]\n",
      " [0.10382132 0.09914597 0.09468417 0.120691   0.10541186 0.08824917\n",
      "  0.08767478 0.0970521  0.10631493 0.09695468]\n",
      " [0.09225154 0.10849775 0.11194079 0.10016236 0.10717917 0.09032248\n",
      "  0.1175739  0.09126014 0.08192508 0.09888689]\n",
      " [0.08870275 0.10131888 0.0980885  0.10898146 0.10970747 0.08519171\n",
      "  0.1129934  0.09254798 0.10529424 0.09717366]\n",
      " [0.09686276 0.10180563 0.10049924 0.11356656 0.10027349 0.10296874\n",
      "  0.1041235  0.09369534 0.09206447 0.09414022]\n",
      " [0.11073101 0.09598781 0.09569483 0.12604599 0.09301797 0.08780817\n",
      "  0.10476371 0.11062888 0.08943638 0.08588529]\n",
      " [0.10861801 0.10460027 0.11236569 0.11139939 0.09533439 0.09374272\n",
      "  0.10181186 0.08711279 0.08285882 0.10215604]\n",
      " [0.09364096 0.09734198 0.09967208 0.10265349 0.09744827 0.0972219\n",
      "  0.10257004 0.10069457 0.10649265 0.10226409]\n",
      " [0.10155179 0.10405555 0.09727457 0.10468157 0.09290455 0.1127943\n",
      "  0.08839541 0.10078502 0.10065547 0.09690173]\n",
      " [0.10263019 0.10249528 0.10362913 0.10103749 0.09649521 0.09229318\n",
      "  0.10593911 0.09777272 0.09558285 0.1021248 ]\n",
      " [0.10276588 0.10499768 0.11367574 0.10891167 0.11093441 0.10881502\n",
      "  0.09318502 0.08803706 0.07945091 0.08922663]\n",
      " [0.09101083 0.11102956 0.10529729 0.11314934 0.10785897 0.09481566\n",
      "  0.09822083 0.09559821 0.0894462  0.0935731 ]\n",
      " [0.09974336 0.11531629 0.10391163 0.10257657 0.09794998 0.11341144\n",
      "  0.09389552 0.09469822 0.09223346 0.08626352]\n",
      " [0.12650965 0.09582891 0.11707278 0.09716451 0.09120979 0.09318881\n",
      "  0.10200432 0.08538257 0.08404785 0.10759078]\n",
      " [0.10442575 0.10129204 0.09688602 0.09707025 0.11003589 0.09758557\n",
      "  0.09306244 0.09566454 0.10575224 0.09822527]\n",
      " [0.10141832 0.09569041 0.09734287 0.10103405 0.10566941 0.08374839\n",
      "  0.11355729 0.09681699 0.1012872  0.10343508]\n",
      " [0.11120655 0.09839574 0.10947268 0.11411115 0.09985574 0.08486548\n",
      "  0.09800899 0.09994201 0.09289913 0.09124255]\n",
      " [0.1071263  0.10823025 0.09625097 0.11076406 0.10046968 0.09255277\n",
      "  0.09203114 0.10818783 0.08867273 0.09571425]\n",
      " [0.09250614 0.09988935 0.09853718 0.10950986 0.10401809 0.08930025\n",
      "  0.11592723 0.08611146 0.10558823 0.09861216]\n",
      " [0.09174131 0.0950573  0.09201468 0.10931642 0.09785444 0.10621414\n",
      "  0.08985803 0.09645639 0.10011148 0.12137587]\n",
      " [0.0935555  0.09441233 0.10343287 0.10722461 0.0996573  0.09137946\n",
      "  0.104165   0.11604732 0.09381396 0.09631166]\n",
      " [0.09657229 0.10365039 0.11123501 0.09395161 0.10531837 0.09667347\n",
      "  0.09951221 0.09195679 0.11159509 0.08953482]\n",
      " [0.10985618 0.09430727 0.1016795  0.10478504 0.11181132 0.09880364\n",
      "  0.09721164 0.0905107  0.0860277  0.10500706]\n",
      " [0.10430206 0.11139369 0.09883933 0.09901229 0.10570633 0.09423126\n",
      "  0.11043795 0.09221263 0.08629087 0.09757354]\n",
      " [0.10241375 0.08834524 0.10502218 0.104224   0.10789251 0.08367756\n",
      "  0.1270043  0.09053782 0.08915794 0.10172465]\n",
      " [0.09121438 0.10263073 0.09139762 0.10371183 0.1055067  0.09957174\n",
      "  0.10264275 0.09806076 0.10396277 0.10130069]\n",
      " [0.11010206 0.11329907 0.11867195 0.10773512 0.11307342 0.08209616\n",
      "  0.09996541 0.09483522 0.0749884  0.08523319]\n",
      " [0.10128471 0.09758648 0.11094534 0.09287485 0.08980475 0.0992082\n",
      "  0.10963395 0.09684481 0.09638599 0.10543093]\n",
      " [0.09617523 0.1024321  0.09813569 0.11946681 0.088774   0.09346351\n",
      "  0.09491313 0.10674979 0.08751816 0.11237159]\n",
      " [0.08565342 0.09837063 0.12261656 0.12012863 0.10018069 0.08623458\n",
      "  0.08546088 0.108785   0.09576149 0.0968081 ]\n",
      " [0.11215001 0.09440327 0.09708447 0.11158931 0.10261533 0.10503405\n",
      "  0.09868956 0.0981339  0.08758988 0.09271015]\n",
      " [0.11557489 0.10452621 0.09578669 0.12371619 0.11798655 0.09073734\n",
      "  0.10320801 0.08239665 0.08218698 0.08388049]\n",
      " [0.11624038 0.11095784 0.10039068 0.10831025 0.0993742  0.09090527\n",
      "  0.09929474 0.08831486 0.08786766 0.09834418]\n",
      " [0.10375397 0.09459455 0.09408991 0.10742863 0.0986631  0.09779559\n",
      "  0.10395392 0.09900994 0.10656383 0.09414658]\n",
      " [0.09288626 0.11281497 0.10481509 0.10687576 0.09874596 0.08175746\n",
      "  0.10349152 0.10933217 0.09837488 0.09090588]\n",
      " [0.1035398  0.10259365 0.11163525 0.10920636 0.1096034  0.07794995\n",
      "  0.11263723 0.09657464 0.09088327 0.08537646]\n",
      " [0.1087096  0.09968255 0.0996226  0.09933707 0.10809042 0.09224104\n",
      "  0.10259556 0.09748048 0.10222799 0.09001269]\n",
      " [0.08990282 0.09553167 0.10354579 0.11187473 0.09977405 0.10033324\n",
      "  0.11050647 0.09392703 0.10010017 0.09450401]\n",
      " [0.10525127 0.10053817 0.11492547 0.10426386 0.09949072 0.09417677\n",
      "  0.09497257 0.10356532 0.08455101 0.09826482]\n",
      " [0.11157982 0.09040726 0.09230282 0.1037494  0.11622588 0.08937059\n",
      "  0.1072631  0.09562521 0.08727915 0.10619671]\n",
      " [0.09889457 0.09951764 0.09978313 0.10786992 0.09838767 0.11115122\n",
      "  0.1030333  0.08310924 0.09081189 0.1074414 ]\n",
      " [0.1009537  0.09435295 0.09855922 0.10667122 0.11639787 0.08591966\n",
      "  0.11477529 0.08577961 0.10013774 0.09645269]\n",
      " [0.12031125 0.09842847 0.10641704 0.10963784 0.09301493 0.11196393\n",
      "  0.08958675 0.08470034 0.1000984  0.08584102]\n",
      " [0.10028505 0.09401521 0.10749105 0.11356036 0.10555853 0.10690642\n",
      "  0.0906805  0.08538198 0.09010506 0.10601582]\n",
      " [0.11607758 0.09892277 0.10775225 0.10438164 0.08860017 0.09274651\n",
      "  0.09803923 0.09233752 0.09832479 0.10281754]\n",
      " [0.09149846 0.10476791 0.09784868 0.11100335 0.10261763 0.09125381\n",
      "  0.10253966 0.10510159 0.10028464 0.09308419]\n",
      " [0.0907315  0.10307855 0.10227096 0.11252491 0.10058581 0.10507796\n",
      "  0.09336494 0.09981127 0.09307899 0.0994751 ]\n",
      " [0.10519285 0.10458288 0.10491756 0.1064049  0.0993319  0.08795009\n",
      "  0.10362587 0.09089088 0.09695769 0.10014541]\n",
      " [0.10127929 0.1022717  0.10084307 0.11595391 0.09252477 0.08725446\n",
      "  0.10809258 0.09732958 0.10703193 0.08741876]\n",
      " [0.10362606 0.10027464 0.10713794 0.1087722  0.10056169 0.0935282\n",
      "  0.09392788 0.09657938 0.09168401 0.10390789]\n",
      " [0.09334007 0.09166768 0.09720363 0.11000169 0.11632343 0.08958019\n",
      "  0.11919914 0.07573479 0.10736303 0.09958631]\n",
      " [0.08615562 0.10028046 0.08958304 0.11448655 0.0922663  0.10610418\n",
      "  0.11741485 0.09007657 0.10455844 0.09907396]\n",
      " [0.10332598 0.09578291 0.08908853 0.10818888 0.10065856 0.09666033\n",
      "  0.11291695 0.0991177  0.09394657 0.10031359]\n",
      " [0.08962903 0.11055753 0.10193744 0.10979404 0.11278005 0.09700599\n",
      "  0.09090776 0.10728481 0.0852799  0.09482346]\n",
      " [0.09414959 0.10025242 0.09531753 0.12231749 0.10921664 0.0836612\n",
      "  0.0999688  0.10277645 0.10015918 0.09218074]\n",
      " [0.10036272 0.09071492 0.10241499 0.11461729 0.10868052 0.09505011\n",
      "  0.10512759 0.08360365 0.10176136 0.09766693]\n",
      " [0.10455451 0.10059974 0.09886068 0.09865814 0.09797288 0.09016664\n",
      "  0.10689713 0.10539237 0.09953201 0.09736594]\n",
      " [0.09378055 0.10771159 0.1013544  0.10585198 0.10800643 0.0892138\n",
      "  0.10314018 0.09676234 0.09489454 0.09928421]\n",
      " [0.07945908 0.09598248 0.11257807 0.10641871 0.12648803 0.08241803\n",
      "  0.10885278 0.0903438  0.09027509 0.10718387]\n",
      " [0.0890699  0.10075057 0.09841817 0.11637827 0.1073073  0.09077077\n",
      "  0.09293421 0.1021517  0.10757536 0.09464382]\n",
      " [0.09673826 0.11163992 0.09514247 0.11554152 0.1151887  0.09197646\n",
      "  0.10793348 0.08997667 0.08634769 0.0895148 ]\n",
      " [0.09993474 0.10939062 0.09319612 0.1165237  0.0971164  0.08924246\n",
      "  0.10405871 0.10008682 0.09665114 0.09379929]\n",
      " [0.1127593  0.09460235 0.10705674 0.10838219 0.10120579 0.08901945\n",
      "  0.08987512 0.09045307 0.09629937 0.11034663]\n",
      " [0.11099806 0.10710806 0.10341839 0.10208961 0.10130318 0.09639586\n",
      "  0.0993313  0.09282596 0.09279095 0.09373869]\n",
      " [0.09501813 0.11209543 0.10786444 0.12177449 0.10393187 0.09767974\n",
      "  0.08914272 0.09920344 0.08470102 0.08858866]\n",
      " [0.10204339 0.10911799 0.10588926 0.11245237 0.09409398 0.10062928\n",
      "  0.09743628 0.09232651 0.08800472 0.09800623]\n",
      " [0.08438116 0.10338372 0.09775118 0.11474688 0.1055792  0.09379435\n",
      "  0.10452776 0.09158985 0.09623069 0.10801521]\n",
      " [0.09791376 0.1003247  0.10096652 0.11967203 0.09135889 0.09540895\n",
      "  0.10558932 0.0924091  0.0901914  0.10616533]\n",
      " [0.10267306 0.10128639 0.09415547 0.10686345 0.11745266 0.08061884\n",
      "  0.10597631 0.0949064  0.09780811 0.09825934]\n",
      " [0.10365593 0.09057803 0.10215539 0.10996164 0.10491358 0.10208516\n",
      "  0.10057033 0.09603889 0.0919212  0.0981198 ]\n",
      " [0.09138671 0.09645426 0.1036726  0.11436579 0.10377298 0.09140324\n",
      "  0.10804381 0.10117382 0.08744241 0.10228437]\n",
      " [0.0949385  0.09840776 0.09740195 0.10545161 0.10763762 0.09867072\n",
      "  0.10747468 0.10289749 0.09596593 0.09115373]\n",
      " [0.1053622  0.09328767 0.11013721 0.10377128 0.11136428 0.1158288\n",
      "  0.09923997 0.08738428 0.08383797 0.08978633]\n",
      " [0.10242158 0.09500569 0.10041361 0.10601841 0.10563054 0.08939131\n",
      "  0.11040445 0.09229396 0.10666139 0.09175903]\n",
      " [0.09676544 0.08565564 0.12357417 0.11299871 0.10476935 0.10876845\n",
      "  0.0974688  0.09301063 0.07622896 0.10075989]\n",
      " [0.09832779 0.10044124 0.10199978 0.10116965 0.11024188 0.09887414\n",
      "  0.10473786 0.1024316  0.08741394 0.09436216]\n",
      " [0.09855208 0.09643746 0.09502605 0.1022729  0.10199085 0.09368476\n",
      "  0.10965557 0.10134935 0.10089234 0.10013862]\n",
      " [0.11232212 0.09926496 0.10156643 0.11400573 0.09610122 0.10800219\n",
      "  0.09462591 0.09387809 0.0873851  0.09284835]\n",
      " [0.09617481 0.10580575 0.10271596 0.10058357 0.09634428 0.10581599\n",
      "  0.0954983  0.09795468 0.09214287 0.10696383]\n",
      " [0.09399007 0.09382284 0.10981332 0.11153749 0.10470293 0.09896509\n",
      "  0.09302896 0.09696145 0.10670628 0.09047157]\n",
      " [0.10750943 0.10003065 0.09746245 0.12092467 0.09773235 0.0933817\n",
      "  0.09150985 0.10520197 0.08764652 0.09860048]\n",
      " [0.10632895 0.0938428  0.09730819 0.10339562 0.09888253 0.10012055\n",
      "  0.11935177 0.08643811 0.09216427 0.10216714]\n",
      " [0.10306631 0.10411128 0.10506497 0.10596704 0.11048944 0.0880264\n",
      "  0.09951487 0.08849803 0.0937984  0.10146327]\n",
      " [0.09561291 0.10697427 0.10769089 0.09952344 0.09836105 0.09916908\n",
      "  0.0954053  0.10409462 0.0940487  0.0991198 ]\n",
      " [0.11213125 0.09718566 0.10613596 0.11015005 0.10136555 0.08880888\n",
      "  0.10113278 0.08697573 0.09166939 0.10444473]\n",
      " [0.08955892 0.09783666 0.10477796 0.10776535 0.10436527 0.09564378\n",
      "  0.10688584 0.09788775 0.09454975 0.10072865]\n",
      " [0.10962685 0.09979828 0.10040154 0.09693273 0.09482067 0.09556944\n",
      "  0.10024994 0.10077503 0.10139475 0.10043072]\n",
      " [0.09473493 0.10529778 0.10137711 0.09294293 0.10174307 0.09469508\n",
      "  0.09707993 0.10912571 0.09578644 0.10721704]\n",
      " [0.10247309 0.09716205 0.10361372 0.1078808  0.10280927 0.09858268\n",
      "  0.0978441  0.09810948 0.09575228 0.09577248]\n",
      " [0.10213367 0.10744463 0.11377747 0.09710279 0.09089352 0.09787131\n",
      "  0.10033066 0.10066172 0.09113812 0.09864607]] (13.287 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.78007\n",
      "INFO:tensorflow:probabilities = [[0.08961342 0.08987811 0.10916932 0.11133704 0.11107831 0.09407359\n",
      "  0.10761923 0.09440965 0.09743056 0.09539078]\n",
      " [0.09204529 0.10370359 0.08191019 0.11451346 0.09878034 0.09981365\n",
      "  0.11326145 0.08627989 0.1037679  0.10592434]\n",
      " [0.09735798 0.09716053 0.09970874 0.11054776 0.1129542  0.09312586\n",
      "  0.09420797 0.09900071 0.09402647 0.10190971]\n",
      " [0.09917784 0.10393734 0.1032813  0.10783672 0.10017015 0.08486502\n",
      "  0.1080485  0.10097692 0.08675741 0.10494874]\n",
      " [0.08659074 0.09665139 0.10220753 0.11703743 0.10739561 0.0889999\n",
      "  0.11210991 0.09634959 0.09958965 0.09306818]\n",
      " [0.09747469 0.10844318 0.10441368 0.09786347 0.08265695 0.12366689\n",
      "  0.09209169 0.10591646 0.09375244 0.09372059]\n",
      " [0.09599418 0.10702419 0.09698565 0.11286202 0.111447   0.09522367\n",
      "  0.10471552 0.08225901 0.09468254 0.09880625]\n",
      " [0.11596268 0.10110598 0.09858908 0.10146937 0.11733107 0.08502146\n",
      "  0.09807087 0.09371312 0.08489575 0.10384063]\n",
      " [0.08900064 0.10106788 0.10786226 0.10671038 0.11532421 0.08703431\n",
      "  0.10332081 0.0974844  0.10503793 0.08715715]\n",
      " [0.12347474 0.08887098 0.11542157 0.1117863  0.08805989 0.1054516\n",
      "  0.09421882 0.08302172 0.09272464 0.09696977]\n",
      " [0.08419511 0.1069079  0.08892707 0.09996422 0.10198369 0.10371903\n",
      "  0.1109615  0.09522694 0.10458829 0.10352627]\n",
      " [0.09388079 0.08717961 0.11212818 0.1197395  0.11565349 0.09867276\n",
      "  0.09034909 0.08946344 0.10111762 0.09181554]\n",
      " [0.09714482 0.095451   0.09240182 0.1013248  0.09960993 0.10158323\n",
      "  0.10406628 0.10438319 0.1047768  0.09925821]\n",
      " [0.10707165 0.09969646 0.10956947 0.09699301 0.09555707 0.09754953\n",
      "  0.09963702 0.09595471 0.09452673 0.1034443 ]\n",
      " [0.09676074 0.09778154 0.10463811 0.11211986 0.09835903 0.10284708\n",
      "  0.09685059 0.09801336 0.09783074 0.09479896]\n",
      " [0.09904491 0.10725293 0.10314337 0.10429957 0.10590447 0.101093\n",
      "  0.09123444 0.10158274 0.10201597 0.08442862]\n",
      " [0.0955087  0.08699776 0.10622938 0.1170686  0.11002609 0.10165589\n",
      "  0.09694725 0.09512699 0.08509186 0.10534751]\n",
      " [0.09691857 0.09919257 0.10463929 0.11323824 0.10363252 0.09665305\n",
      "  0.09612446 0.09932881 0.09382715 0.09644538]\n",
      " [0.11691222 0.09367047 0.10227922 0.09835543 0.09555141 0.11863241\n",
      "  0.10791381 0.08136471 0.07770621 0.10761416]\n",
      " [0.09023008 0.09717053 0.08462192 0.11276346 0.11464003 0.09547234\n",
      "  0.10887126 0.08352178 0.11007138 0.10263721]\n",
      " [0.11777534 0.10924634 0.11451244 0.11017038 0.09832947 0.0938364\n",
      "  0.09741312 0.08323196 0.07967185 0.09581275]\n",
      " [0.10181522 0.10145859 0.10675996 0.10826302 0.10403089 0.0960116\n",
      "  0.0957244  0.09164204 0.09466394 0.09963033]\n",
      " [0.08706346 0.10276357 0.09358577 0.10776098 0.10537224 0.09908777\n",
      "  0.10018568 0.10161324 0.10285605 0.09971119]\n",
      " [0.09951835 0.10295523 0.09307504 0.11127071 0.10241041 0.09540096\n",
      "  0.10223407 0.09787652 0.09220912 0.10304962]\n",
      " [0.12082206 0.08890086 0.12784515 0.10383988 0.09917476 0.08620505\n",
      "  0.09191631 0.0919043  0.09437507 0.09501664]\n",
      " [0.11376209 0.08591378 0.12564926 0.10426299 0.0995551  0.10093407\n",
      "  0.09360038 0.08314378 0.09022864 0.10294987]\n",
      " [0.12323534 0.09542372 0.11766956 0.092665   0.09791273 0.10446981\n",
      "  0.09167986 0.08232271 0.10029162 0.09432967]\n",
      " [0.10269941 0.10087349 0.10959337 0.10345909 0.09482103 0.10580195\n",
      "  0.09848588 0.07598285 0.1042764  0.10400656]\n",
      " [0.08263778 0.10019653 0.09138743 0.10893621 0.09533814 0.0934779\n",
      "  0.11092868 0.0984383  0.11360645 0.10505263]\n",
      " [0.10188113 0.0989136  0.08990297 0.11796679 0.10574212 0.08874281\n",
      "  0.10159002 0.10125799 0.09097956 0.10302298]\n",
      " [0.1059849  0.1029515  0.1134323  0.09463134 0.09748019 0.09768102\n",
      "  0.10965358 0.09051483 0.08832975 0.09934054]\n",
      " [0.12428021 0.10076062 0.08388555 0.1146521  0.09155137 0.09364565\n",
      "  0.08999343 0.09380911 0.10896961 0.09845238]\n",
      " [0.09962185 0.10677049 0.08900151 0.11103351 0.10683186 0.07897796\n",
      "  0.12949957 0.0980607  0.08822247 0.09198003]\n",
      " [0.13019775 0.08665154 0.10088415 0.09942005 0.0884617  0.09956986\n",
      "  0.10007725 0.09898859 0.10125504 0.09449408]\n",
      " [0.09918673 0.10063204 0.09765257 0.1168657  0.10265508 0.09206287\n",
      "  0.09709466 0.08962174 0.10280823 0.10142039]\n",
      " [0.10284451 0.10597497 0.10089226 0.1140074  0.10408032 0.09451189\n",
      "  0.09992063 0.08515682 0.09168623 0.10092495]\n",
      " [0.10464387 0.09153704 0.10618157 0.10779598 0.09766474 0.09146127\n",
      "  0.10634307 0.09841633 0.09636676 0.09958931]\n",
      " [0.09396287 0.10247686 0.10312425 0.09577606 0.11863194 0.09995524\n",
      "  0.10370387 0.07875839 0.10029434 0.10331614]\n",
      " [0.11069059 0.10108078 0.10481834 0.11035278 0.11525341 0.09872828\n",
      "  0.09069604 0.09617399 0.08087465 0.09133117]\n",
      " [0.10675659 0.09500978 0.10369901 0.11065505 0.10216974 0.09200372\n",
      "  0.09554226 0.10269531 0.10388604 0.08758245]\n",
      " [0.12069529 0.10062052 0.10790668 0.11146188 0.10178085 0.10484045\n",
      "  0.10589658 0.07647208 0.07809463 0.09223104]\n",
      " [0.10986612 0.10064483 0.10562622 0.10742374 0.0981739  0.10385876\n",
      "  0.09488203 0.09161957 0.08952412 0.09838071]\n",
      " [0.09441055 0.10032646 0.09416463 0.10894877 0.09438225 0.10320785\n",
      "  0.1029347  0.09558795 0.10134985 0.10468698]\n",
      " [0.10483092 0.09994795 0.11035163 0.1019531  0.10217679 0.09595297\n",
      "  0.10571906 0.09650239 0.08920492 0.09336028]\n",
      " [0.10780443 0.10182316 0.08638235 0.11357149 0.09283005 0.09892304\n",
      "  0.10869939 0.10443434 0.10200905 0.08352269]\n",
      " [0.09700674 0.09505171 0.10964584 0.09607007 0.10111447 0.09480688\n",
      "  0.11674727 0.08388112 0.08772267 0.11795327]\n",
      " [0.09265656 0.09534848 0.09735241 0.11856771 0.09800857 0.09827882\n",
      "  0.10335398 0.09983799 0.09180083 0.10479464]\n",
      " [0.10945985 0.10269341 0.11346003 0.11598717 0.0886304  0.09134094\n",
      "  0.10005079 0.08241411 0.10297374 0.09298957]\n",
      " [0.08647215 0.10684466 0.09490497 0.10452938 0.10230299 0.09743553\n",
      "  0.10853324 0.09750112 0.09205551 0.10942052]\n",
      " [0.09982515 0.10698926 0.09542768 0.10764251 0.12234876 0.09255098\n",
      "  0.09752046 0.09192491 0.09344205 0.09232824]\n",
      " [0.09865374 0.09759633 0.1200131  0.105096   0.11331352 0.08649338\n",
      "  0.10634039 0.08672596 0.09018382 0.09558384]\n",
      " [0.10181817 0.11834911 0.1070675  0.09586248 0.10582992 0.08726259\n",
      "  0.08809713 0.11520373 0.09161089 0.08889855]\n",
      " [0.09788224 0.08850593 0.11228529 0.10573743 0.09259647 0.11023888\n",
      "  0.09653433 0.09335825 0.09901623 0.10384491]\n",
      " [0.1089154  0.09778354 0.11149175 0.10088256 0.07845759 0.09646724\n",
      "  0.11177987 0.10233453 0.08166468 0.11022282]\n",
      " [0.1106862  0.1000949  0.09332968 0.1072515  0.10179522 0.0892469\n",
      "  0.11838456 0.0916658  0.09316697 0.09437826]\n",
      " [0.11670638 0.09793204 0.1129939  0.11655659 0.10361934 0.09072409\n",
      "  0.08290455 0.09348961 0.09524638 0.08982714]\n",
      " [0.10600596 0.10121106 0.0962714  0.10804424 0.10054414 0.10647814\n",
      "  0.09671371 0.08621708 0.09136422 0.1071501 ]\n",
      " [0.08660255 0.09477402 0.10673845 0.10933188 0.10122499 0.10526214\n",
      "  0.10179846 0.08988255 0.10031406 0.10407096]\n",
      " [0.10666677 0.09640642 0.10869491 0.106778   0.11210752 0.0934763\n",
      "  0.09879759 0.0942221  0.07993241 0.10291788]\n",
      " [0.1066491  0.09338745 0.10908338 0.10931878 0.10172389 0.10756741\n",
      "  0.09874026 0.09323427 0.0861809  0.09411457]\n",
      " [0.10038883 0.10082819 0.12158874 0.0979647  0.11201099 0.11031906\n",
      "  0.09289078 0.09245826 0.09145837 0.08009207]\n",
      " [0.09795956 0.09762263 0.10065334 0.11307842 0.10623046 0.10328732\n",
      "  0.08846349 0.10277664 0.09682586 0.09310227]\n",
      " [0.09171337 0.10168663 0.10192933 0.11835263 0.09818655 0.09428683\n",
      "  0.10133624 0.09775127 0.09568541 0.09907179]\n",
      " [0.10459099 0.09968874 0.09496403 0.12621829 0.09461694 0.09460829\n",
      "  0.09805458 0.09791326 0.10096396 0.08838093]\n",
      " [0.12038094 0.1109055  0.11995948 0.0876449  0.09078836 0.10547306\n",
      "  0.08843338 0.0950591  0.0813919  0.09996338]\n",
      " [0.09010308 0.10435071 0.10223097 0.10854    0.1118071  0.09490371\n",
      "  0.1081011  0.11497418 0.07870372 0.08628548]\n",
      " [0.09545019 0.11790136 0.10143851 0.10829051 0.0976422  0.09898288\n",
      "  0.08105221 0.10761129 0.09984647 0.09178436]\n",
      " [0.0965874  0.08936125 0.10123272 0.10257917 0.11331318 0.10421755\n",
      "  0.10670839 0.10190729 0.08859754 0.0954955 ]\n",
      " [0.09523223 0.09971248 0.09709719 0.10973496 0.09894732 0.08736411\n",
      "  0.10736962 0.09163947 0.09956136 0.11334127]\n",
      " [0.10005439 0.1006088  0.09454477 0.10565758 0.10791119 0.10087289\n",
      "  0.09937231 0.09931724 0.0920005  0.09966026]\n",
      " [0.10288546 0.10269866 0.10476901 0.10685607 0.10875145 0.08767642\n",
      "  0.10342123 0.10236236 0.09426625 0.0863131 ]\n",
      " [0.09162362 0.10974372 0.08819572 0.10119804 0.11209546 0.10840247\n",
      "  0.09905782 0.108023   0.09140314 0.09025698]\n",
      " [0.1068152  0.10080481 0.0936508  0.10903694 0.10197446 0.10180603\n",
      "  0.09665272 0.10109057 0.09099159 0.09717683]\n",
      " [0.09926422 0.09009646 0.11259297 0.09103896 0.09370431 0.09397662\n",
      "  0.11200076 0.09821855 0.10400898 0.10509816]\n",
      " [0.09515682 0.09793244 0.10928998 0.11592776 0.11284195 0.08806376\n",
      "  0.10347725 0.09429523 0.0872933  0.0957215 ]\n",
      " [0.10543211 0.09051636 0.11990751 0.11047757 0.10039005 0.0832357\n",
      "  0.10389867 0.09435267 0.08918896 0.10260044]\n",
      " [0.11490732 0.09457667 0.09426943 0.11260967 0.10077267 0.09727442\n",
      "  0.09753779 0.10128127 0.09463952 0.09213115]\n",
      " [0.09447253 0.10304502 0.0991214  0.10272522 0.09820758 0.09481233\n",
      "  0.09960473 0.10294844 0.09545454 0.10960828]\n",
      " [0.09803607 0.10488883 0.09600532 0.10983907 0.10776561 0.09128066\n",
      "  0.09724655 0.09849745 0.092091   0.10434949]\n",
      " [0.1175888  0.10990974 0.09589717 0.08953153 0.09733869 0.1036635\n",
      "  0.09895283 0.09871597 0.0823542  0.10604747]\n",
      " [0.13340175 0.10166244 0.09977476 0.10942951 0.08809406 0.09971625\n",
      "  0.09684076 0.09064724 0.08950099 0.09093224]\n",
      " [0.11472862 0.10259352 0.09827564 0.09809127 0.12103168 0.10143826\n",
      "  0.09833679 0.08430942 0.08316397 0.09803085]\n",
      " [0.10022625 0.09652662 0.10322829 0.10509159 0.11974059 0.09744678\n",
      "  0.10080726 0.09924597 0.0780252  0.09966149]\n",
      " [0.12002466 0.09240457 0.10851795 0.10894351 0.09923402 0.09825755\n",
      "  0.09484742 0.08847856 0.09890419 0.09038761]\n",
      " [0.09817401 0.1022731  0.10597748 0.10572117 0.11194947 0.09136962\n",
      "  0.09792975 0.09491146 0.10434874 0.08734513]\n",
      " [0.10884003 0.10002922 0.10732101 0.11187465 0.08782803 0.09429266\n",
      "  0.10573036 0.09606875 0.09696603 0.09104922]\n",
      " [0.1031174  0.10784248 0.09011637 0.10521828 0.10649063 0.09500025\n",
      "  0.0871926  0.09358902 0.10321483 0.10821812]\n",
      " [0.10709799 0.08987918 0.12400195 0.10181987 0.11171115 0.09572762\n",
      "  0.11359493 0.09562656 0.06975003 0.09079068]\n",
      " [0.1198191  0.1082086  0.10571957 0.10949692 0.10381749 0.08865216\n",
      "  0.09534379 0.09547441 0.08681902 0.0866489 ]\n",
      " [0.0934762  0.11123649 0.11420134 0.11990698 0.10085487 0.09674241\n",
      "  0.09334582 0.08524238 0.08766997 0.09732356]\n",
      " [0.10289221 0.10260342 0.08993431 0.10826993 0.11824639 0.09506791\n",
      "  0.08915962 0.09270955 0.10106507 0.10005163]\n",
      " [0.09838986 0.10266463 0.12479199 0.11187214 0.0931082  0.08768371\n",
      "  0.09489258 0.08230255 0.09709066 0.10720374]\n",
      " [0.09488235 0.10735106 0.09775854 0.10421688 0.10440505 0.09594861\n",
      "  0.10694514 0.09644417 0.09049079 0.10155742]\n",
      " [0.11442003 0.10650248 0.1169104  0.09943592 0.09326728 0.09157266\n",
      "  0.09249461 0.10033465 0.08958028 0.09548174]\n",
      " [0.09682283 0.10335293 0.1065609  0.09428698 0.10156482 0.09817658\n",
      "  0.1112202  0.11098354 0.10023245 0.07679873]\n",
      " [0.08950919 0.10469235 0.09408622 0.11730193 0.09941955 0.10157015\n",
      "  0.10813196 0.09718239 0.09374941 0.09435683]\n",
      " [0.10626411 0.10698798 0.09095106 0.1098334  0.10675927 0.07625449\n",
      "  0.09581529 0.108326   0.10508186 0.09372649]\n",
      " [0.08829451 0.09287473 0.10872051 0.09890383 0.11791137 0.08961824\n",
      "  0.10428015 0.10227878 0.09427755 0.10284033]\n",
      " [0.11552554 0.0957356  0.12326434 0.10168161 0.08760403 0.0960203\n",
      "  0.1192954  0.07997721 0.08166306 0.09923292]\n",
      " [0.09526077 0.09264146 0.10568619 0.12024284 0.11955464 0.08637507\n",
      "  0.10213853 0.09270999 0.08722048 0.09817011]] (13.168 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2752316, step = 201 (26.454 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ef0f5c999278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-13970e3f79bb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         hooks=[logging_hook])\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Evaluate the model and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1023\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
