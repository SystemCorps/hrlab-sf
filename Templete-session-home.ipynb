{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 640\n",
    "height = 480\n",
    "pix = [height, width]\n",
    "num_chan = 3\n",
    "num_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 921600)\n"
     ]
    }
   ],
   "source": [
    "# torn: 0-1484\n",
    "# untorn: 0-1779\n",
    "num_torn = 129\n",
    "num_untorn = 129\n",
    "total_pix = width*height*num_chan\n",
    "\n",
    "torn_data = np.zeros((num_torn, total_pix), dtype=np.float32)\n",
    "print(torn_data.shape)\n",
    "untorn_data = np.zeros((num_untorn, total_pix), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128]\n",
      "[ 50 119 107  12 126  63  74  92 103 116  70   7  67 112 110  94  33  85\n",
      " 118  11  56 124   9 127  96  64 115  88  51 105  54  45  42  21  81 102\n",
      "  53  32  22  62  80  82  35  97  41  31  38   2  55  43 101  59 106  37\n",
      "  72 122  40  17 120 121 117  48  83  98  69   5   1 114  13 108   3  66\n",
      "  44 100 125 128  93  19  27  18  75  14  76  28  71  34  29  10   0  58\n",
      "  60  16  91 104  23 111  95  87   4  39  36  89  99  61  26  46  65  90\n",
      "  25  47  24  73  52  78  15  49 109  57  84  30  86  68  77   6   8  20\n",
      " 123 113  79]\n"
     ]
    }
   ],
   "source": [
    "torn_idx = np.arange(num_torn)\n",
    "untorn_idx = np.arange(num_untorn)\n",
    "print(torn_idx)\n",
    "\n",
    "np.random.shuffle(torn_idx)\n",
    "np.random.shuffle(untorn_idx)\n",
    "\n",
    "print(torn_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torn_label = np.full((num_torn,1), 1, dtype=np.float32)\n",
    "untorn_label = np.full((num_untorn,1), 1, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 26\n",
      "103 26\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "# Training 80%, evaluation 20%\n",
    "# Training data rate\n",
    "tr_rate = 0.8\n",
    "\n",
    "\n",
    "num_tr_torn = int(tr_rate * num_torn)\n",
    "num_ev_torn = num_torn - num_tr_torn\n",
    "print(num_tr_torn, num_ev_torn)\n",
    "\n",
    "num_tr_untorn = int(tr_rate * num_untorn)\n",
    "num_ev_untorn = num_untorn - num_tr_untorn\n",
    "print(num_tr_untorn, num_ev_untorn)\n",
    "\n",
    "tr_torn_idx = torn_idx[:num_tr_torn]\n",
    "ev_torn_idx = torn_idx[num_tr_torn:]\n",
    "\n",
    "tr_untorn_idx = untorn_idx[:num_tr_untorn]\n",
    "ev_untorn_idx = untorn_idx[num_tr_untorn:]\n",
    "\n",
    "\n",
    "tr_idx = np.append(tr_torn_idx, tr_untorn_idx)\n",
    "ev_idx = np.append(ev_torn_idx, ev_untorn_idx)\n",
    "\n",
    "tr_label = np.append(np.full((num_tr_torn), 1, dtype=np.int32), np.full((num_tr_untorn), 0, dtype=np.int32))\n",
    "ev_label = np.append(np.full((num_ev_torn), 1, dtype=np.int32), np.full((num_ev_untorn), 0, dtype=np.int32))\n",
    "\n",
    "print(tr_label[num_tr_torn-1], tr_label[num_tr_torn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "tr_shuf_idx = np.arange(tr_label.shape[0])\n",
    "np.random.shuffle(tr_shuf_idx)\n",
    "\n",
    "ev_shuf_idx = np.arange(ev_label.shape[0])\n",
    "np.random.shuffle(ev_shuf_idx)\n",
    "\n",
    "\n",
    "tr_data_shuf = np.zeros((tr_label.shape[0], total_pix), dtype = np.float32)\n",
    "tr_label_shuf = np.zeros(tr_label.shape[0], dtype=np.int32)\n",
    "\n",
    "\n",
    "ev_data_shuf = np.zeros((ev_label.shape[0], total_pix), dtype = np.float32)\n",
    "ev_label_shuf = np.zeros(ev_label.shape[0], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(tr_label.shape[0]):\n",
    "    if tr_label[tr_shuf_idx[i]] == 1:\n",
    "        tr_label_shuf[i] = 1\n",
    "        img = cv2.imread(\"D:/dataset/torn/img-%04d.png\" % tr_idx[tr_shuf_idx[i]]).flatten()\n",
    "        tr_data_shuf[i][:] = img\n",
    "        \n",
    "    else:\n",
    "        tr_label_shuf[i] = 0\n",
    "        img = cv2.imread(\"D:/dataset/untorn/img-%04d.png\" % tr_idx[tr_shuf_idx[i]]).flatten()      \n",
    "        tr_data_shuf[i][:] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(ev_label.shape[0]):\n",
    "    if ev_label[ev_shuf_idx[i]] == 1:\n",
    "        ev_label_shuf[i] = 1\n",
    "        img = cv2.imread(\"D:/dataset/torn/img-%04d.png\" % ev_idx[ev_shuf_idx[i]]).flatten()\n",
    "        ev_data_shuf[i][:] = img\n",
    "        \n",
    "    else:\n",
    "        ev_label_shuf[i] = 0\n",
    "        img = cv2.imread(\"D:/dataset/untorn/img-%04d.png\" % ev_idx[ev_shuf_idx[i]]).flatten()\n",
    "        ev_data_shuf[i][:] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "today = datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today = datetime.today().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "np.savetxt(\"./data_index/tr_idx-%s.csv\" % today, tr_shuf_idx, delimiter=',')\n",
    "np.savetxt(\"./data_index/tr_label-%s.csv\" % today, tr_label_shuf, delimiter=',')\n",
    "\n",
    "\n",
    "np.savetxt(\"./data_index/ev_idx-%s.csv\" % today, ev_shuf_idx, delimiter=',')\n",
    "np.savetxt(\"./data_index/ev_label-%s.csv\" % today, ev_label_shuf, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(shape):\n",
    "    return tf.Varaible(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, total_pix])\n",
    "#Y = tf.placeholder(\"float\", [None, num_class])\n",
    "Y = tf.placeholder(\"int32\", [None, 1])\n",
    "p_keep = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features):\n",
    "    \n",
    "    # For dropout\n",
    "    keep_rate = 0.5\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, height, width, channels]\n",
    "    # Our Fishing net image size is 640x480 and 3-channel (RGB)\n",
    "    input_layer = tf.reshape(features, [-1, 480, 640, 3])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 48 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 480, 640, 3]\n",
    "    # Output Tensor Shape: [batch_size, 480, 640, 48]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        \n",
    "        inputs=input_layer,\n",
    "        filters=48,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 480, 640, 48]\n",
    "    # Output Tensor Shape: [batch_size, 240, 320, 48]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    #pool1 = tf.nn.dropout(pool1, keep_rate)\n",
    "    \n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 96 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 240, 320, 48]\n",
    "    # Output Tensor Shape: [batch_size, 240, 320, 96]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 240, 320, 96]\n",
    "    # Output Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    #pool2 = tf.nn.dropout(pool2, keep_rate)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    # Output Tensor Shape: [batch_size, 120, 160, 96]    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    # Output Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    #pool3 = tf.nn.dropout(pool3, keep_rate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    # Output Tensor Shape: [batch_size, 60, 80, 96]    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    # Output Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    #pool4 = tf.nn.dropout(pool4, keep_rate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    # Output Tensor Shape: [batch_size, 30, 40, 96]    \n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=pool4,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    # Output Tensor Shape: [batch_size, 15, 20, 96]\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2)\n",
    "    #pool5 = tf.nn.dropout(pool5, keep_rate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 15, 20, 96]\n",
    "    # Output Tensor Shape: [batch_size, 15 * 20 * 96]\n",
    "    pool5_flat = tf.reshape(pool5, [-1, 15 * 20 * 96])\n",
    "    \n",
    "\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 15 * 20 * 96]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool5_flat, units=1024, activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=(1-keep_rate))\n",
    "    \n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 1]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "py_x = cnn_model_fn(X)\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels = Y, logits = py_x)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 921600)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "x_in = tr_data_shuf[i*batch_size:(i+1)*batch_size]\n",
    "y_temp = tr_label_shuf[i*batch_size:(i+1)*batch_size]\n",
    "print(x_in.shape)\n",
    "print(y_temp.shape)\n",
    "y_in = y_temp.reshape([batch_size,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 921600) (32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_in.shape, y_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,96,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, max_pooling2d_1/MaxPool, gradients/conv2d_2/Conv2D_grad/tuple/control_dependency)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"c:\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 596, in launch_instance\n    app.start()\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"c:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-40256e9d4974>\", line 5, in <module>\n    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 359, in minimize\n    grad_loss=grad_loss)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 460, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 611, in gradients\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 377, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 611, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 604, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3716, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'max_pooling2d_1/MaxPool', defined at:\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 17 identical lines from previous traceback]\n  File \"c:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-40256e9d4974>\", line 1, in <module>\n    py_x = cnn_model_fn(X)\n  File \"<ipython-input-13-28d93884bd5f>\", line 49, in cnn_model_fn\n    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\pooling.py\", line 433, in max_pooling2d\n    return layer.apply(inputs)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 809, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 696, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\pooling.py\", line 277, in call\n    data_format=utils.convert_data_format(self.data_format, 4))\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2124, in max_pool\n    name=name)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3422, in _max_pool\n    data_format=data_format, name=name)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,96,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, max_pooling2d_1/MaxPool, gradients/conv2d_2/Conv2D_grad/tuple/control_dependency)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,96,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, max_pooling2d_1/MaxPool, gradients/conv2d_2/Conv2D_grad/tuple/control_dependency)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2e6808451e41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_in\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,96,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, max_pooling2d_1/MaxPool, gradients/conv2d_2/Conv2D_grad/tuple/control_dependency)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad', defined at:\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"c:\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 596, in launch_instance\n    app.start()\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"c:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-40256e9d4974>\", line 5, in <module>\n    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 359, in minimize\n    grad_loss=grad_loss)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 460, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 611, in gradients\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 377, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 611, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\", line 604, in _MaxPoolGrad\n    data_format=op.get_attr(\"data_format\"))\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3716, in _max_pool_grad\n    data_format=data_format, name=name)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'max_pooling2d_1/MaxPool', defined at:\n  File \"c:\\anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 17 identical lines from previous traceback]\n  File \"c:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-40256e9d4974>\", line 1, in <module>\n    py_x = cnn_model_fn(X)\n  File \"<ipython-input-13-28d93884bd5f>\", line 49, in cnn_model_fn\n    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\pooling.py\", line 433, in max_pooling2d\n    return layer.apply(inputs)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 809, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 696, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\pooling.py\", line 277, in call\n    data_format=utils.convert_data_format(self.data_format, 4))\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2124, in max_pool\n    name=name)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 3422, in _max_pool\n    data_format=data_format, name=name)\n  File \"c:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,96,240,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, max_pooling2d_1/MaxPool, gradients/conv2d_2/Conv2D_grad/tuple/control_dependency)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "sess.run(train_op, feed_dict={X: x_in, Y: y_in})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "#training_steps = int(epoch*tr_label_shuf.shape[0]/batch_size)\n",
    "training_steps = 1\n",
    "\n",
    "#tr_idx_select = np.arange(tr_label_shuf.shape[0])\n",
    "\n",
    "# without random selection\n",
    "for i in range(training_steps):\n",
    "    \n",
    "    \n",
    "    if i != range(training_steps)[-1]:\n",
    "        x_in = tr_data_shuf[i*batch_size:(i+1)*batch_size]\n",
    "        y_temp = tr_label_shuf[i*batch_size:(i+1)*batch_size]\n",
    "        y_in = y_temp.reshape([batch_size,1])\n",
    "    else:\n",
    "        x_in = tr_data_shuf[i*batch_size:]\n",
    "        y_temp = tr_label_shuf[i*batch_size:(i+1)*batch_size]\n",
    "        y_in = y_temp.reshape([batch_size,1])\n",
    "        \n",
    "        \n",
    "    sess.run(train_op, feed_dict={X: x_in, Y: y_in})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
