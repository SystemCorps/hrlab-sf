{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 640\n",
    "height = 480\n",
    "pix = [height, width]\n",
    "num_chan = 3\n",
    "num_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torn: 0-1484\n",
    "# untorn: 0-1779\n",
    "num_torn = 129\n",
    "num_untorn = 129\n",
    "total_pix = width*height*num_chan\n",
    "\n",
    "torn_data = np.zeros((num_torn, total_pix), dtype=np.float32)\n",
    "print(torn_data.shape)\n",
    "untorn_data = np.zeros((num_untorn, total_pix), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torn_idx = np.arange(num_torn)\n",
    "untorn_idx = np.arange(num_untorn)\n",
    "print(torn_idx)\n",
    "\n",
    "np.random.shuffle(torn_idx)\n",
    "np.random.shuffle(untorn_idx)\n",
    "\n",
    "print(torn_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torn_label = np.full((num_torn,1), 1, dtype=np.float32)\n",
    "untorn_label = np.full((num_untorn,1), 1, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 80%, evaluation 20%\n",
    "# Training data rate\n",
    "tr_rate = 0.8\n",
    "\n",
    "\n",
    "num_tr_torn = int(tr_rate * num_torn)\n",
    "num_ev_torn = num_torn - num_tr_torn\n",
    "print(num_tr_torn, num_ev_torn)\n",
    "\n",
    "num_tr_untorn = int(tr_rate * num_untorn)\n",
    "num_ev_untorn = num_untorn - num_tr_untorn\n",
    "print(num_tr_untorn, num_ev_untorn)\n",
    "\n",
    "tr_torn_idx = torn_idx[:num_tr_torn]\n",
    "ev_torn_idx = torn_idx[num_tr_torn:]\n",
    "\n",
    "tr_untorn_idx = untorn_idx[:num_tr_untorn]\n",
    "ev_untorn_idx = untorn_idx[num_tr_untorn:]\n",
    "\n",
    "\n",
    "tr_idx = np.append(tr_torn_idx, tr_untorn_idx)\n",
    "ev_idx = np.append(ev_torn_idx, ev_untorn_idx)\n",
    "\n",
    "tr_label = np.append(np.full((num_tr_torn), 1, dtype=np.int32), np.full((num_tr_untorn), 0, dtype=np.int32))\n",
    "ev_label = np.append(np.full((num_ev_torn), 1, dtype=np.int32), np.full((num_ev_untorn), 0, dtype=np.int32))\n",
    "\n",
    "print(tr_label[num_tr_torn-1], tr_label[num_tr_torn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "tr_shuf_idx = np.arange(tr_label.shape[0])\n",
    "np.random.shuffle(tr_shuf_idx)\n",
    "\n",
    "ev_shuf_idx = np.arange(ev_label.shape[0])\n",
    "np.random.shuffle(ev_shuf_idx)\n",
    "\n",
    "\n",
    "tr_data_shuf = np.zeros((tr_label.shape[0], total_pix), dtype = np.float32)\n",
    "tr_label_shuf = np.zeros(tr_label.shape[0], dtype=np.int32)\n",
    "\n",
    "\n",
    "ev_data_shuf = np.zeros((ev_label.shape[0], total_pix), dtype = np.float32)\n",
    "ev_label_shuf = np.zeros(ev_label.shape[0], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tr_label.shape[0]):\n",
    "    if tr_label[tr_shuf_idx[i]] == 1:\n",
    "        tr_label_shuf[i] = 1\n",
    "        img = cv2.imread(\"/dataset/torn/img-%04d.png\" % tr_idx[tr_shuf_idx[i]]).flatten()\n",
    "        tr_data_shuf[i][:] = img\n",
    "        \n",
    "    else:\n",
    "        tr_label_shuf[i] = 0\n",
    "        img = cv2.imread(\"/dataset/untorn/img-%04d.png\" % tr_idx[tr_shuf_idx[i]]).flatten()      \n",
    "        tr_data_shuf[i][:] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ev_label.shape[0]):\n",
    "    if ev_label[ev_shuf_idx[i]] == 1:\n",
    "        ev_label_shuf[i] = 1\n",
    "        img = cv2.imread(\"/dataset/torn/img-%04d.png\" % ev_idx[ev_shuf_idx[i]]).flatten()\n",
    "        ev_data_shuf[i][:] = img\n",
    "        \n",
    "    else:\n",
    "        ev_label_shuf[i] = 0\n",
    "        img = cv2.imread(\"/dataset/untorn/img-%04d.png\" % ev_idx[ev_shuf_idx[i]]).flatten()\n",
    "        ev_data_shuf[i][:] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(shape):\n",
    "    return tf.Varaible(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, total_pix])\n",
    "#Y = tf.placeholder(\"float\", [None, num_class])\n",
    "Y = tf.placeholder(\"int32\", [None, 1])\n",
    "p_keep = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features):\n",
    "    \n",
    "    # For dropout\n",
    "    keep_rate = 0.5\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, height, width, channels]\n",
    "    # Our Fishing net image size is 640x480 and 3-channel (RGB)\n",
    "    input_layer = tf.reshape(features, [-1, 480, 640, 3])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 48 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 480, 640, 3]\n",
    "    # Output Tensor Shape: [batch_size, 480, 640, 48]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        \n",
    "        inputs=input_layer,\n",
    "        filters=48,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 480, 640, 48]\n",
    "    # Output Tensor Shape: [batch_size, 240, 320, 48]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    #pool1 = tf.nn.dropout(pool1, keep_rate)\n",
    "    \n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 96 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 240, 320, 48]\n",
    "    # Output Tensor Shape: [batch_size, 240, 320, 96]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 240, 320, 96]\n",
    "    # Output Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    #pool2 = tf.nn.dropout(pool2, keep_rate)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    # Output Tensor Shape: [batch_size, 120, 160, 96]    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    # Output Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    #pool3 = tf.nn.dropout(pool3, keep_rate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    # Output Tensor Shape: [batch_size, 60, 80, 96]    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    # Output Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    #pool4 = tf.nn.dropout(pool4, keep_rate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    # Output Tensor Shape: [batch_size, 30, 40, 96]    \n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=pool4,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    # Output Tensor Shape: [batch_size, 15, 20, 96]\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2)\n",
    "    #pool5 = tf.nn.dropout(pool5, keep_rate)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 15, 20, 96]\n",
    "    # Output Tensor Shape: [batch_size, 15 * 20 * 96]\n",
    "    pool5_flat = tf.reshape(pool5, [-1, 15 * 20 * 96])\n",
    "    \n",
    "\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 15 * 20 * 96]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool5_flat, units=1024, activation=tf.nn.relu)\n",
    "    \n",
    "    \n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=(1-keep_rate))\n",
    "    \n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 1]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "py_x = cnn_model_fn(X)\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels = Y, logits = py_x)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "x_in = tr_data_shuf[i*batch_size:(i+1)*batch_size]\n",
    "y_temp = tr_label_shuf[i*batch_size:(i+1)*batch_size]\n",
    "print(x_in.shape)\n",
    "print(y_temp.shape)\n",
    "y_in = y_temp.reshape([batch_size,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_in.shape, y_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(train_op, feed_dict={X: x_in, Y: y_in})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "#training_steps = int(epoch*tr_label_shuf.shape[0]/batch_size)\n",
    "training_steps = 1\n",
    "\n",
    "#tr_idx_select = np.arange(tr_label_shuf.shape[0])\n",
    "\n",
    "# without random selection\n",
    "for i in range(training_steps):\n",
    "    \n",
    "    \n",
    "    if i != range(training_steps)[-1]:\n",
    "        x_in = tr_data_shuf[i*batch_size:(i+1)*batch_size]\n",
    "        y_temp = tr_label_shuf[i*batch_size:(i+1)*batch_size]\n",
    "        y_in = y_temp.reshape([batch_size,1])\n",
    "    else:\n",
    "        x_in = tr_data_shuf[i*batch_size:]\n",
    "        y_temp = tr_label_shuf[i*batch_size:(i+1)*batch_size]\n",
    "        y_in = y_temp.reshape([batch_size,1])\n",
    "        \n",
    "        \n",
    "    sess.run(train_op, feed_dict={X: x_in, Y: y_in})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
