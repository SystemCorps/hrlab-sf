{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Trainig Templete\n",
    "## Based on Tensorlfow - CNN MNIST example\n",
    "https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/examples/tutorials/layers/cnn_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 library 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "import json\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# GPU selection (memory)\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_txt = open('./data_split/data_dir_0801.txt', 'r')\n",
    "data_json = data_txt.read()\n",
    "tr_data_dir = json.loads(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info.\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "channel = 3\n",
    "\n",
    "\n",
    "# resize\n",
    "r_w = 224\n",
    "r_h = 224\n",
    "\n",
    "total_pix = r_w * r_h * channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dataset_full/Torn/Torn (780).png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data_dir['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dir = '/hdd3/dhj_container/DB'\n",
    "\n",
    "tr_data = np.zeros((len(tr_data_dir['train']), total_pix), dtype=np.float32)\n",
    "tr_label = np.zeros((len(tr_data_dir['train']), 1), dtype=np.int32)\n",
    "\n",
    "for i in range(len(tr_data_dir['train'])):\n",
    "    img = cv2.imread(add_dir+tr_data_dir['train'][i])\n",
    "    img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "    tr_data[i,:] = img2.flatten()\n",
    "    \n",
    "    if 'Untorn' in tr_data_dir['train'][i]:\n",
    "        tr_label[i] = 0\n",
    "    elif 'normal' in tr_data_dir['train'][i]:\n",
    "        tr_label[i] = 0\n",
    "        \n",
    "    else:\n",
    "        tr_label[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = np.zeros((len(tr_data_dir['valid']), total_pix), dtype=np.float32)\n",
    "val_label = np.zeros((len(tr_data_dir['valid']), 1), dtype=np.int32)\n",
    "\n",
    "for j in range(len(val_data)):\n",
    "    img = cv2.imread(add_dir+tr_data_dir['valid'][j])\n",
    "    img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "    val_data[j,:] = img2.flatten()\n",
    "\n",
    "    if 'Untorn' in tr_data_dir['valid'][j]:\n",
    "        val_label[j] = 0\n",
    "    elif 'normal' in tr_data_dir['valid'][j]:\n",
    "        val_label[j] = 0\n",
    "\n",
    "    else:\n",
    "        val_label[j] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(features, labels, mode):\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, height, width, channels]\n",
    "    # Our Fishing net image size is 640x480 and 3-channel (RGB)\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 224, 224, 3])\n",
    "    dropout_keep_prob = 0.5\n",
    "    num_classes = 2\n",
    "    is_training = True\n",
    "    \n",
    "    \n",
    "    net = layers_lib.repeat(\n",
    "        input_layer, 2, layers.conv2d, 64, [3, 3], scope='conv1')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool1')\n",
    "    net = layers_lib.repeat(net, 2, layers.conv2d, 128, [3, 3], scope='conv2')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 256, [3, 3], scope='conv3')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool3')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 512, [3, 3], scope='conv4')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool4')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 512, [3, 3], scope='conv5')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool5')\n",
    "    # Use conv2d instead of fully_connected layers.\n",
    "    net = layers.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "    net = layers_lib.dropout(\n",
    "        net, dropout_keep_prob, is_training=is_training, scope='dropout6')\n",
    "    net = layers.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "    net = layers_lib.dropout(\n",
    "        net, dropout_keep_prob, is_training=is_training, scope='dropout7')\n",
    "    net = layers.conv2d(\n",
    "        net,\n",
    "        num_classes, [1, 1],\n",
    "        activation_fn=None,\n",
    "        normalizer_fn=None,\n",
    "        scope='fc8')\n",
    "    net = array_ops.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "    \n",
    "    logits = net\n",
    "    \n",
    "\n",
    "    with tf.device('/GPU:3'):\n",
    "\n",
    "        predictions = {\n",
    "            # Generate predictions (for PREDICT and EVAL mode)\n",
    "            \"classes\": tf.argmax(input=logits, axis=1),\n",
    "            # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "            # `logging_hook`.\n",
    "            \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        # sparse_softmax_cross_entropy cannot use one-hot encoding\n",
    "\n",
    "        #loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "        # Configure the Training Op (for TRAIN mode)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.000001)\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "        # Add evaluation metrics (for EVAL mode)\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\": tf.metrics.accuracy(\n",
    "                labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_log_step_count_steps': 100, '_evaluation_master': '', '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_task_id': 0, '_model_dir': '/host_hdd3/dhj_container/temp/', '_global_id_in_cluster': 0, '_service': None, '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f122f8fa198>, '_save_summary_steps': 100, '_session_config': None, '_task_type': 'worker', '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_master': '', '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /host_hdd3/dhj_container/temp/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.36122262 0.6387774 ]\n",
      " [0.4056689  0.5943311 ]\n",
      " [0.4105445  0.5894555 ]\n",
      " [0.46134675 0.5386532 ]\n",
      " [0.4582006  0.54179937]\n",
      " [0.43337008 0.5666299 ]\n",
      " [0.3843969  0.6156031 ]\n",
      " [0.5069606  0.49303943]\n",
      " [0.3972407  0.60275924]\n",
      " [0.43564707 0.5643529 ]\n",
      " [0.4839575  0.51604253]\n",
      " [0.46513325 0.53486675]\n",
      " [0.39614022 0.60385984]\n",
      " [0.49793527 0.5020647 ]\n",
      " [0.49768817 0.5023118 ]\n",
      " [0.37021834 0.6297816 ]\n",
      " [0.48837796 0.511622  ]\n",
      " [0.42868268 0.5713173 ]\n",
      " [0.2676798  0.73232013]\n",
      " [0.5316655  0.46833447]\n",
      " [0.45372313 0.54627687]\n",
      " [0.45982856 0.54017144]\n",
      " [0.5155304  0.48446956]\n",
      " [0.5309455  0.46905455]\n",
      " [0.554116   0.44588396]\n",
      " [0.42859644 0.57140356]\n",
      " [0.578714   0.42128593]\n",
      " [0.5425561  0.4574439 ]\n",
      " [0.4631487  0.5368513 ]\n",
      " [0.4891577  0.5108423 ]\n",
      " [0.29013917 0.70986086]\n",
      " [0.5265699  0.4734301 ]]\n",
      "INFO:tensorflow:step = 1, loss = 0.72169846\n",
      "INFO:tensorflow:probabilities = [[0.5122807  0.48771933]\n",
      " [0.4820411  0.5179589 ]\n",
      " [0.44585663 0.55414337]\n",
      " [0.51222366 0.48777637]\n",
      " [0.65216863 0.3478314 ]\n",
      " [0.584183   0.41581708]\n",
      " [0.2823842  0.71761584]\n",
      " [0.5774107  0.4225893 ]\n",
      " [0.55982447 0.4401755 ]\n",
      " [0.43650958 0.56349045]\n",
      " [0.41737896 0.58262104]\n",
      " [0.6462658  0.35373423]\n",
      " [0.3460538  0.65394616]\n",
      " [0.5218797  0.47812033]\n",
      " [0.55285233 0.44714767]\n",
      " [0.4738201  0.52617997]\n",
      " [0.67572296 0.324277  ]\n",
      " [0.44529602 0.55470395]\n",
      " [0.27005863 0.72994137]\n",
      " [0.43536946 0.5646305 ]\n",
      " [0.40668756 0.59331244]\n",
      " [0.4815649  0.51843506]\n",
      " [0.46307972 0.5369203 ]\n",
      " [0.5148288  0.48517117]\n",
      " [0.35369405 0.646306  ]\n",
      " [0.61229116 0.38770887]\n",
      " [0.5528626  0.44713742]\n",
      " [0.57180697 0.4281931 ]\n",
      " [0.3045712  0.6954288 ]\n",
      " [0.61184114 0.38815886]\n",
      " [0.30949768 0.6905023 ]\n",
      " [0.44820535 0.55179465]] (16.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06179\n",
      "INFO:tensorflow:probabilities = [[0.29075858 0.7092414 ]\n",
      " [0.71503437 0.28496563]\n",
      " [0.1822922  0.8177078 ]\n",
      " [0.6659081  0.33409196]\n",
      " [0.2759874  0.7240126 ]\n",
      " [0.51831484 0.48168516]\n",
      " [0.23102729 0.7689727 ]\n",
      " [0.57405686 0.42594317]\n",
      " [0.50681114 0.49318892]\n",
      " [0.274581   0.72541904]\n",
      " [0.58587795 0.41412205]\n",
      " [0.5837626  0.4162374 ]\n",
      " [0.7039803  0.29601964]\n",
      " [0.55545866 0.44454134]\n",
      " [0.5860898  0.41391018]\n",
      " [0.30530468 0.6946953 ]\n",
      " [0.5499765  0.4500235 ]\n",
      " [0.6501025  0.34989747]\n",
      " [0.6459487  0.35405132]\n",
      " [0.6792004  0.32079962]\n",
      " [0.64541477 0.35458523]\n",
      " [0.29689178 0.7031082 ]\n",
      " [0.62823    0.37176996]\n",
      " [0.58137065 0.41862935]\n",
      " [0.34176284 0.65823716]\n",
      " [0.6590383  0.3409617 ]\n",
      " [0.6861964  0.31380358]\n",
      " [0.29119134 0.70880866]\n",
      " [0.5835721  0.41642788]\n",
      " [0.56084746 0.43915248]\n",
      " [0.6253242  0.3746758 ]\n",
      " [0.3000726  0.69992745]] (16.237 sec)\n",
      "INFO:tensorflow:step = 101, loss = 0.66617465 (32.661 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 114 into /host_hdd3/dhj_container/temp/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.6453937.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-08-02:39:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /host_hdd3/dhj_container/temp/model.ckpt-114\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:probabilities = [[0.5969055  0.40309444]\n",
      " [0.65133375 0.3486663 ]\n",
      " [0.224868   0.775132  ]\n",
      " [0.20517126 0.7948287 ]\n",
      " [0.33466095 0.66533905]\n",
      " [0.46456864 0.5354314 ]\n",
      " [0.59297335 0.40702668]\n",
      " [0.6929276  0.3070724 ]\n",
      " [0.24910574 0.7508943 ]\n",
      " [0.6472681  0.35273185]\n",
      " [0.19156455 0.8084355 ]\n",
      " [0.45704356 0.5429565 ]\n",
      " [0.6429559  0.35704416]\n",
      " [0.25390422 0.7460957 ]\n",
      " [0.54794484 0.45205513]\n",
      " [0.6376304  0.3623696 ]\n",
      " [0.56753343 0.4324666 ]\n",
      " [0.75380296 0.24619704]\n",
      " [0.48641884 0.5135811 ]\n",
      " [0.7128368  0.2871632 ]\n",
      " [0.11360283 0.88639724]\n",
      " [0.12661125 0.87338877]\n",
      " [0.65929854 0.34070146]\n",
      " [0.24093436 0.7590657 ]\n",
      " [0.6935007  0.30649933]\n",
      " [0.65713096 0.34286904]\n",
      " [0.37601936 0.6239806 ]\n",
      " [0.6613182  0.3386818 ]\n",
      " [0.5998635  0.40013647]\n",
      " [0.42647916 0.57352084]\n",
      " [0.7465341  0.25346586]\n",
      " [0.69215083 0.30784917]\n",
      " [0.7139309  0.28606915]\n",
      " [0.548063   0.45193705]\n",
      " [0.68543935 0.31456068]\n",
      " [0.14055496 0.85944504]\n",
      " [0.2713703  0.7286297 ]\n",
      " [0.2515691  0.7484309 ]\n",
      " [0.4957395  0.5042605 ]\n",
      " [0.5118224  0.4881776 ]\n",
      " [0.6256591  0.3743409 ]\n",
      " [0.2624907  0.7375093 ]\n",
      " [0.75431615 0.24568388]\n",
      " [0.32379895 0.67620105]\n",
      " [0.6074468  0.3925532 ]\n",
      " [0.16162287 0.8383771 ]\n",
      " [0.13604198 0.863958  ]\n",
      " [0.5964491  0.40355086]\n",
      " [0.59598917 0.40401086]\n",
      " [0.57774943 0.42225057]\n",
      " [0.59636796 0.40363201]\n",
      " [0.59351766 0.40648234]\n",
      " [0.5648506  0.43514934]\n",
      " [0.69818354 0.30181646]\n",
      " [0.63071615 0.36928383]\n",
      " [0.19518721 0.8048128 ]\n",
      " [0.6250377  0.3749623 ]\n",
      " [0.14352918 0.85647076]\n",
      " [0.69935614 0.30064386]\n",
      " [0.4807797  0.5192203 ]\n",
      " [0.65914786 0.3408521 ]\n",
      " [0.61166215 0.38833785]\n",
      " [0.22033839 0.77966166]\n",
      " [0.18287429 0.81712574]]\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-08-02:39:12\n",
      "INFO:tensorflow:Saving dict for global step 114: accuracy = 0.720524, global_step = 114, loss = 0.5721355\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /host_hdd3/dhj_container/temp/model.ckpt-114\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 115 into /host_hdd3/dhj_container/temp/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.2863128  0.7136872 ]\n",
      " [0.5247544  0.47524565]\n",
      " [0.6866522  0.31334785]\n",
      " [0.62239087 0.37760916]\n",
      " [0.7133566  0.28664342]\n",
      " [0.656521   0.34347898]\n",
      " [0.23395447 0.7660456 ]\n",
      " [0.52463055 0.47536945]\n",
      " [0.55192614 0.44807386]\n",
      " [0.5655102  0.43448976]\n",
      " [0.7523165  0.24768348]\n",
      " [0.6007869  0.39921302]\n",
      " [0.38367948 0.61632055]\n",
      " [0.2870481  0.7129519 ]\n",
      " [0.1161832  0.88381684]\n",
      " [0.6128017  0.38719827]\n",
      " [0.16452564 0.8354744 ]\n",
      " [0.15339938 0.8466006 ]\n",
      " [0.15760241 0.84239763]\n",
      " [0.23407586 0.76592416]\n",
      " [0.54924667 0.4507533 ]\n",
      " [0.69431704 0.30568296]\n",
      " [0.2553996  0.7446004 ]\n",
      " [0.29499564 0.7050044 ]\n",
      " [0.20635684 0.7936431 ]\n",
      " [0.19630851 0.8036915 ]\n",
      " [0.15539111 0.84460884]\n",
      " [0.26954758 0.7304524 ]\n",
      " [0.6508013  0.3491987 ]\n",
      " [0.52491033 0.4750897 ]\n",
      " [0.6127777  0.38722226]\n",
      " [0.62120634 0.3787936 ]]\n",
      "INFO:tensorflow:step = 115, loss = 0.45655188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-421d52453c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_in_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             hooks=[logging_hook])\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogging_hook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1023\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "#session = tf.Session(config=config)\n",
    "for i in range(4,5):\n",
    "    \n",
    "# Create the Estimator\n",
    "# RL 1=0.001, 2=0.0001, 3=0.00001, 4=0.000001\n",
    "    f_dir = \"/hdd3/dhj_container/temp/\" \n",
    "\n",
    "    if not tf.gfile.Exists(f_dir):\n",
    "        tf.gfile.MakeDirs(f_dir)\n",
    "\n",
    "    net_classifier = tf.estimator.Estimator(\n",
    "        model_fn=vgg16, model_dir=f_dir)\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "    batch_s = 32\n",
    "    epochs = 30\n",
    "    tr_steps = int(tr_data.shape[0]/batch_s*epochs)\n",
    "    step_in_epoch = int(tr_data.shape[0]/batch_s)+1\n",
    "    in_steps = 1\n",
    "\n",
    "\n",
    "    for ee in range(epochs):\n",
    "        \n",
    "        train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": tr_data},\n",
    "            y=tr_label,\n",
    "            batch_size=batch_s,\n",
    "            num_epochs=1,\n",
    "            shuffle=False)\n",
    "\n",
    "        eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": val_data},\n",
    "            y=val_label,\n",
    "            batch_size=64,\n",
    "            num_epochs=1,\n",
    "            shuffle=False)\n",
    "\n",
    "        net_classifier.train(\n",
    "            input_fn=train_input_fn,\n",
    "            steps=step_in_epoch,\n",
    "            hooks=[logging_hook])\n",
    "\n",
    "        eval_results = net_classifier.evaluate(input_fn=eval_input_fn, hooks=[logging_hook])\n",
    "        temp_res = eval_results[\"accuracy\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
