{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "import json\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# GPU selection (memory)\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_txt = open('./data_split/5fold_0802.txt', 'r')\n",
    "data_json = data_txt.read()\n",
    "tr_data_dir = json.loads(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info.\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "channel = 3\n",
    "\n",
    "\n",
    "# resize\n",
    "r_w = 224\n",
    "r_h = 224\n",
    "\n",
    "total_pix = r_w * r_h * channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dataset_full/Torn/Torn (1220).png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data_dir['train0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(features, labels, mode):\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, height, width, channels]\n",
    "    # Our Fishing net image size is 640x480 and 3-channel (RGB)\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 224, 224, 3])\n",
    "    dropout_keep_prob = 0.5\n",
    "    num_classes = 2\n",
    "    is_training = True\n",
    "    \n",
    "    \n",
    "    net = layers_lib.repeat(\n",
    "        input_layer, 2, layers.conv2d, 64, [3, 3], scope='conv1')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool1')\n",
    "    net = layers_lib.repeat(net, 2, layers.conv2d, 128, [3, 3], scope='conv2')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 256, [3, 3], scope='conv3')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool3')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 512, [3, 3], scope='conv4')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool4')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 512, [3, 3], scope='conv5')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool5')\n",
    "    # Use conv2d instead of fully_connected layers.\n",
    "    net = layers.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "    net = layers_lib.dropout(\n",
    "        net, dropout_keep_prob, is_training=is_training, scope='dropout6')\n",
    "    net = layers.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "    net = layers_lib.dropout(\n",
    "        net, dropout_keep_prob, is_training=is_training, scope='dropout7')\n",
    "    net = layers.conv2d(\n",
    "        net,\n",
    "        num_classes, [1, 1],\n",
    "        activation_fn=None,\n",
    "        normalizer_fn=None,\n",
    "        scope='fc8')\n",
    "    net = array_ops.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "    \n",
    "    logits = net\n",
    "    \n",
    "\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    acc = tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "\n",
    "    tf.summary.scalar('train_acc', acc[1])\n",
    "    # sparse_softmax_cross_entropy cannot use one-hot encoding\n",
    "\n",
    "    #loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_service': None, '_tf_random_seed': None, '_task_type': 'worker', '_save_checkpoints_steps': None, '_is_chief': True, '_global_id_in_cluster': 0, '_evaluation_master': '', '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe66cba71d0>, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_num_ps_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_model_dir': '/hdd3/dhj_container/ICROS_vgg/kfold0811_3/'}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 100 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 0.6884763\n",
      "INFO:tensorflow:global_step/sec: 3.06221\n",
      "INFO:tensorflow:step = 101, loss = 0.49923763 (32.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.05258\n",
      "INFO:tensorflow:step = 201, loss = 0.42808533 (32.758 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 257 into /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.58480394.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-11-04:45:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt-257\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-11-04:45:43\n",
      "INFO:tensorflow:Saving dict for global step 257: accuracy = 0.7160088, global_step = 257, loss = 0.5790156\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt-257\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 258 into /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt.\n",
      "INFO:tensorflow:step = 258, loss = 0.5071255\n",
      "INFO:tensorflow:global_step/sec: 3.03652\n",
      "INFO:tensorflow:step = 358, loss = 0.46786398 (32.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02041\n",
      "INFO:tensorflow:step = 458, loss = 0.40579334 (33.108 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 522 into /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3414523.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-11-04:47:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt-522\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-11-04:47:37\n",
      "INFO:tensorflow:Saving dict for global step 522: accuracy = 0.8278509, global_step = 522, loss = 0.39068\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt-522\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 523 into /hdd3/dhj_container/ICROS_vgg/kfold0811_3/model.ckpt.\n"
     ]
    }
   ],
   "source": [
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "#session = tf.Session(config=config)\n",
    "\n",
    "k = 3\n",
    "total_res = {}\n",
    "add_dir = '/hdd3/dhj_container/DB'\n",
    "\n",
    "\n",
    "val_result = []\n",
    "\n",
    "f_dir = \"/hdd3/dhj_container/ICROS_vgg/kfold0811_%d/\" % k\n",
    "\n",
    "if not tf.gfile.Exists(f_dir):\n",
    "    tf.gfile.MakeDirs(f_dir)\n",
    "\n",
    "net_classifier = tf.estimator.Estimator(\n",
    "    model_fn=vgg16, model_dir=f_dir)\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "\n",
    "\n",
    "tr_data = np.zeros((len(tr_data_dir['train%d'%k]), total_pix), dtype=np.float32)\n",
    "tr_label = np.zeros((len(tr_data_dir['train%d'%k]), 1), dtype=np.int32)\n",
    "\n",
    "for j in range(len(tr_data)):\n",
    "    img = cv2.imread(add_dir+tr_data_dir['train%d'%k][j])\n",
    "    img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "    tr_data[j,:] = img2.flatten()\n",
    "\n",
    "    if 'Untorn' in tr_data_dir['train%d'%k][j]:\n",
    "        tr_label[j] = 0\n",
    "    elif 'normal' in tr_data_dir['train%d'%k][j]:\n",
    "        tr_label[j] = 0\n",
    "\n",
    "    else:\n",
    "        tr_label[j] = 1\n",
    "\n",
    "\n",
    "val_data = np.zeros((len(tr_data_dir['valid%d'%k]), total_pix), dtype=np.float32)\n",
    "val_label = np.zeros((len(tr_data_dir['valid%d'%k]), 1), dtype=np.int32)\n",
    "\n",
    "for j in range(len(val_data)):\n",
    "    img = cv2.imread(add_dir+tr_data_dir['valid%d'%k][j])\n",
    "    img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "    val_data[j,:] = img2.flatten()\n",
    "\n",
    "    if 'Untorn' in tr_data_dir['valid%d'%k][j]:\n",
    "        val_label[j] = 0\n",
    "    elif 'normal' in tr_data_dir['valid%d'%k][j]:\n",
    "        val_label[j] = 0\n",
    "\n",
    "    else:\n",
    "        val_label[j] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_s = 32\n",
    "epochs = 30\n",
    "tr_steps = int(tr_data.shape[0]/batch_s*epochs)\n",
    "step_in_epoch = int(tr_data.shape[0]/batch_s)+1\n",
    "in_steps = 1\n",
    "\n",
    "\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": tr_data},\n",
    "    y=tr_label,\n",
    "    batch_size=batch_s,\n",
    "    num_epochs=epochs,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": val_data},\n",
    "    y=val_label,\n",
    "    batch_size=64,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=tr_steps)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, steps=None, throttle_secs=100)\n",
    "\n",
    "tf.estimator.train_and_evaluate(net_classifier, train_spec, eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
