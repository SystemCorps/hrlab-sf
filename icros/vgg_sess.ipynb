{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "import json\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# GPU selection (memory)\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU selection (memory)\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_txt = open('./data_split/5fold_0802.txt', 'r')\n",
    "data_json = data_txt.read()\n",
    "tr_data_dir = json.loads(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info.\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "channel = 3\n",
    "\n",
    "\n",
    "# resize\n",
    "r_w = 224\n",
    "r_h = 224\n",
    "\n",
    "total_pix = r_w * r_h * channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(features, labels, mode):\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, height, width, channels]\n",
    "    # Our Fishing net image size is 640x480 and 3-channel (RGB)\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 224, 224, 3])\n",
    "    dropout_keep_prob = 0.5\n",
    "    num_classes = 2\n",
    "    is_training = True\n",
    "    \n",
    "    \n",
    "    net = layers_lib.repeat(\n",
    "        input_layer, 2, layers.conv2d, 64, [3, 3], scope='conv1')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool1')\n",
    "    net = layers_lib.repeat(net, 2, layers.conv2d, 128, [3, 3], scope='conv2')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 256, [3, 3], scope='conv3')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool3')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 512, [3, 3], scope='conv4')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool4')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 512, [3, 3], scope='conv5')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool5')\n",
    "    # Use conv2d instead of fully_connected layers.\n",
    "    net = layers.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "    net = layers_lib.dropout(\n",
    "        net, dropout_keep_prob, is_training=is_training, scope='dropout6')\n",
    "    net = layers.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "    net = layers_lib.dropout(\n",
    "        net, dropout_keep_prob, is_training=is_training, scope='dropout7')\n",
    "    net = layers.conv2d(\n",
    "        net,\n",
    "        num_classes, [1, 1],\n",
    "        activation_fn=None,\n",
    "        normalizer_fn=None,\n",
    "        scope='fc8')\n",
    "    net = array_ops.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "    \n",
    "    logits = net.layers.dropout(dense1, rate=dropout, training=is_training, name='drop')\n",
    "        \n",
    "    # Output\n",
    "    out = tf.layers.dense(dropout, n_class, name='output')\n",
    "    out = tf.nn.softmax(out) if not is_training else out\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5\n",
    "learning_rate = 0.0001\n",
    "batch_size = 16\n",
    "disp_step = 20\n",
    "save_step = 500\n",
    "n_classes = 2\n",
    "epochs = 10\n",
    "\n",
    "tr_steps = int(tr_data.shape[0]/batch_size*epochs)\n",
    "inner_steps = int((tr_data.shape[0])/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    reuse_vars = False\n",
    "    \n",
    "    # tf graph input\n",
    "    X = tf.placeholder(tf.float32, [None, total_pix], name='inputs')\n",
    "    Y = tf.placeholder(tf.int32, [None, 1], name='labels')\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        # cnn_model(x, n_class, dropout, re_use, is_training, width, height)\n",
    "        logits_train = cnn_model(X, n_classes, dropout, reuse=reuse_vars,\n",
    "                                 is_training=True)\n",
    "        \n",
    "        logits_test = cnn_model(X, n_classes, dropout, reuse=True,\n",
    "                                is_training=False)\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(logits=logits_train, labels=Y)\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        grads = optimizer.compute_gradients(loss)\n",
    "        \n",
    "        pred = tf.argmax(input=logits_test, axis=1)\n",
    "        correct_pred = tf.equal(pred, tf.cast(Y, tf.int64))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        #accuracy = tf.metrics.accuracy(labels=Y, predictions=pred)\n",
    "        \n",
    "        \n",
    "        prob = tf.nn.softmax(logits_test, name='softmax_tensor')\n",
    "        \n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        \n",
    "        reuse_vars = True\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init_g)\n",
    "        sess.run(init_l)\n",
    "\n",
    "        t_count = 1\n",
    "        saver.save(sess, './models/test')\n",
    "        for j in range(epochs):\n",
    "\n",
    "            for i in range(inner_steps):\n",
    "\n",
    "                tr_batch = {}\n",
    "\n",
    "                if i < inner_steps-1:\n",
    "                    tr_batch['data'] = tr_data[i*batch_size:(i+1)*batch_size][:]\n",
    "                    tr_batch['label'] = tr_label[i*batch_size:(i+1)*batch_size][:]\n",
    "\n",
    "                else:\n",
    "                    tr_batch['data'] = tr_data[i*batch_size:][:]\n",
    "                    tr_batch['label'] = tr_label[i*batch_size:][:]\n",
    "\n",
    "                sess.run(train_op, feed_dict={X: tr_batch['data'],\n",
    "                                              Y: tr_batch['label']})\n",
    "\n",
    "                if t_count % disp_step == 1:\n",
    "                    \n",
    "                    loss_tr = sess.run(loss, feed_dict = {X: tr_batch['data'],\n",
    "                                                          Y: tr_batch['label']})\n",
    "\n",
    "                    acc_tr = sess.run(accuracy, feed_dict = {X: tr_batch['data'],\n",
    "                                                             Y: tr_batch['label']})\n",
    "                    \n",
    "                    prob_tr = sess.run(prob, feed_dict = {X: tr_batch['data'],\n",
    "                                                         Y: tr_batch['label']})\n",
    "\n",
    "                    #print('step %d, training accuracy %f, loss %f' % (t_count, accuracy, loss))\n",
    "                    print('Training step: ', t_count)\n",
    "                    print('Accuracy', acc_tr)\n",
    "                    print('Probability')\n",
    "                    print(prob_tr)\n",
    "                    print('Loss: ', loss_tr)\n",
    "                    #print(acc_tr, loss_tr)\n",
    "                    \n",
    "                if t_count % save_step == 0:\n",
    "                    saver.save(sess, './models/test', t_count)\n",
    "\n",
    "                t_count = t_count+1\n",
    "        \n",
    "        saver.save(sess, './models/test', t_count)\n",
    "        print(\"Training is finished!!!\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        ev_accuracy = np.zeros((len(ev_label), 1))\n",
    "        for k in range(len(ev_label)):\n",
    "            ev_batch = {}\n",
    "            ev_batch['data'] = ev_data[k:(k+1)][:]\n",
    "            ev_batch['label'] = ev_label[k:(k+1)]\n",
    "            ev_accuracy[k] = sess.run(accuracy, feed_dict={X: ev_batch['data'],\n",
    "                                                           Y: ev_batch['label']})\n",
    "\n",
    "        print(np.mean(ev_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
