{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "import json\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# GPU selection (memory)\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_txt = open('./data_split/5fold_0802.txt', 'r')\n",
    "data_json = data_txt.read()\n",
    "tr_data_dir = json.loads(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data info.\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "channel = 3\n",
    "\n",
    "\n",
    "# resize\n",
    "r_w = 224\n",
    "r_h = 224\n",
    "\n",
    "total_pix = r_w * r_h * channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dataset_full/Torn/Torn (1220).png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data_dir['train0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg16(features, labels, mode):\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, height, width, channels]\n",
    "    # Our Fishing net image size is 640x480 and 3-channel (RGB)\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 224, 224, 3])\n",
    "    dropout_keep_prob = 0.5\n",
    "    num_classes = 2\n",
    "    is_training = True\n",
    "    \n",
    "    \n",
    "    net = layers_lib.repeat(\n",
    "        input_layer, 2, layers.conv2d, 64, [3, 3], scope='conv1')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool1')\n",
    "    net = layers_lib.repeat(net, 2, layers.conv2d, 128, [3, 3], scope='conv2')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 256, [3, 3], scope='conv3')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool3')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 512, [3, 3], scope='conv4')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool4')\n",
    "    net = layers_lib.repeat(net, 3, layers.conv2d, 512, [3, 3], scope='conv5')\n",
    "    net = layers_lib.max_pool2d(net, [2, 2], scope='pool5')\n",
    "    # Use conv2d instead of fully_connected layers.\n",
    "    net = layers.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "    net = layers_lib.dropout(\n",
    "        net, dropout_keep_prob, is_training=is_training, scope='dropout6')\n",
    "    net = layers.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "    net = layers_lib.dropout(\n",
    "        net, dropout_keep_prob, is_training=is_training, scope='dropout7')\n",
    "    net = layers.conv2d(\n",
    "        net,\n",
    "        num_classes, [1, 1],\n",
    "        activation_fn=None,\n",
    "        normalizer_fn=None,\n",
    "        scope='fc8')\n",
    "    net = array_ops.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "    \n",
    "    logits = net\n",
    "    \n",
    "\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    acc = tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "\n",
    "    tf.summary.scalar('train_acc', acc[1])\n",
    "    # sparse_softmax_cross_entropy cannot use one-hot encoding\n",
    "\n",
    "    #loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"valid_accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "#session = tf.Session(config=config)\n",
    "\n",
    "k = 1\n",
    "total_res = {}\n",
    "add_dir = 'D:'\n",
    "\n",
    "for i in range(k):\n",
    "    val_result = []\n",
    "\n",
    "    f_dir = \"F:/ICROS_vgg/kfold0810_%d/\" % i\n",
    "\n",
    "    if not tf.gfile.Exists(f_dir):\n",
    "        tf.gfile.MakeDirs(f_dir)\n",
    "\n",
    "    net_classifier = tf.estimator.Estimator(\n",
    "        model_fn=vgg16, model_dir=f_dir)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=50)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tr_data = np.zeros((len(tr_data_dir['train%d'%i]), total_pix), dtype=np.float32)\n",
    "    tr_label = np.zeros((len(tr_data_dir['train%d'%i]), 1), dtype=np.int32)\n",
    "\n",
    "    for j in range(len(tr_data)):\n",
    "        img = cv2.imread(add_dir+tr_data_dir['train%d'%i][j])\n",
    "        img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "        tr_data[j,:] = img2.flatten()\n",
    "\n",
    "        if 'Untorn' in tr_data_dir['train%d'%i][j]:\n",
    "            tr_label[j] = 0\n",
    "        elif 'normal' in tr_data_dir['train%d'%i][j]:\n",
    "            tr_label[j] = 0\n",
    "\n",
    "        else:\n",
    "            tr_label[j] = 1\n",
    "\n",
    "    \n",
    "    val_data = np.zeros((len(tr_data_dir['valid%d'%i]), total_pix), dtype=np.float32)\n",
    "    val_label = np.zeros((len(tr_data_dir['valid%d'%i]), 1), dtype=np.int32)\n",
    "\n",
    "    for j in range(len(val_data)):\n",
    "        img = cv2.imread(add_dir+tr_data_dir['valid%d'%i][j])\n",
    "        img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "        val_data[j,:] = img2.flatten()\n",
    "\n",
    "        if 'Untorn' in tr_data_dir['valid%d'%i][j]:\n",
    "            val_label[j] = 0\n",
    "        elif 'normal' in tr_data_dir['valid%d'%i][j]:\n",
    "            val_label[j] = 0\n",
    "\n",
    "        else:\n",
    "            val_label[j] = 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    batch_s = 32\n",
    "    epochs = 5\n",
    "    tr_steps = int(tr_data.shape[0]/batch_s*epochs)\n",
    "    step_in_epoch = int(tr_data.shape[0]/batch_s)+1\n",
    "    in_steps = 1\n",
    "\n",
    "\n",
    "     #for ee in range(epochs):\n",
    "        \n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": tr_data},\n",
    "        y=tr_label,\n",
    "        batch_size=batch_s,\n",
    "        num_epochs=epochs,\n",
    "        shuffle=False)\n",
    "\n",
    "\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": val_data},\n",
    "        y=val_label,\n",
    "        batch_size=64,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, steps=None, start_delay_secs=60, throttle_secs=60)\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(net_classifier, train_spec, eval_spec)\n",
    "\n",
    "    \"\"\"\n",
    "    net_classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=step_in_epoch,\n",
    "        hooks=[logging_hook])\n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "        #train_acc = net_classifier.evaluate(input_fn=train_acc_input_fn, hooks=[logging_hook])\n",
    "        #train_res = train_acc[\"accuracy\"]\n",
    "        \n",
    "        #eval_results = net_classifier.evaluate(input_fn=eval_input_fn, hooks=[logging_hook])\n",
    "        #eval_res = eval_results[\"valid_accuracy\"]\n",
    "\n",
    "        #total_res['%d'%i][ee] = temp_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
