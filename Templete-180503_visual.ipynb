{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Trainig Templete\n",
    "## Based on Tensorlfow - CNN MNIST example\n",
    "https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/examples/tutorials/layers/cnn_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 library 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 640\n",
    "height = 480\n",
    "channel = 3\n",
    "total_pix = width * height * channel\n",
    "num_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(d_dir, split_rate):\n",
    "    \n",
    "    num_class = len(d_dir.keys())\n",
    "\n",
    "    out = {}\n",
    "    \n",
    "\n",
    "    for i in range(num_class):\n",
    "        x_train, x_test = train_test_split(d_dir[i], test_size=split_rate)\n",
    "        \n",
    "        if i == 0:\n",
    "            train_temp = x_train\n",
    "            test_temp = x_test\n",
    "        else:\n",
    "            train_temp.extend(x_train)\n",
    "            test_temp.extend(x_test)\n",
    "    \n",
    "    random.shuffle(train_temp)\n",
    "    out['train'] = train_temp\n",
    "    random.shuffle(test_temp)\n",
    "    out['test'] = test_temp\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780\n"
     ]
    }
   ],
   "source": [
    "image_dir1 = '/dataset/'\n",
    "class_name1 = ['untorn', 'torn']\n",
    "\n",
    "data_dir1 = {}\n",
    "for i in range(len(class_name1)):\n",
    "    temp_dir = image_dir1 + class_name1[i]\n",
    "    img_files = [[os.path.join(temp_dir, f), np.int16(i)] for f in os.listdir(temp_dir) if f.endswith('.png')]\n",
    "    data_dir1[i] = img_files\n",
    "print(len(data_dir1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_dir = data_process(data_dir1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = np.zeros((len(tr_data_dir['train']), total_pix), dtype=np.float32)\n",
    "tr_label = np.zeros((len(tr_data_dir['train']), 1), dtype=np.int32)\n",
    "\n",
    "for i in range(len(tr_data_dir['train'])):\n",
    "    img = cv2.imread(tr_data_dir['train'][i][0])\n",
    "    tr_data[i][:] = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC).flatten()\n",
    "    tr_label[i] = tr_data_dir['train'][i][1]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "ev_data = np.zeros((len(tr_data_dir['test']), total_pix), dtype=np.float32)\n",
    "ev_label = np.zeros((len(tr_data_dir['test']), 1), dtype=np.int32)\n",
    "\n",
    "for i in range(len(tr_data_dir['test'])):\n",
    "    img = cv2.imread(tr_data_dir['test'][i][0])\n",
    "    ev_data[i][:] = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC).flatten()\n",
    "    ev_label[i] = tr_data_dir['test'][i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_label = np.zeros((len(tr_data_dir['train']), 2), dtype=np.float32)\n",
    "\n",
    "for i in range(len(tr_data_dir['train'])):\n",
    "    if tr_data_dir['train'][i][1] == 0:\n",
    "        tr_label[i][0] = 1\n",
    "        tr_label[i][1] = 0\n",
    "    \n",
    "    else:\n",
    "        tr_label[i][0] = 0\n",
    "        tr_label[i][1] = 1\n",
    "    \n",
    "    \n",
    "\n",
    "ev_label = np.zeros((len(tr_data_dir['test']), 2), dtype=np.float32)\n",
    "\n",
    "for i in range(len(tr_data_dir['test'])):\n",
    "    if tr_data_dir['test'][i][1] == 0:\n",
    "        ev_label[i][0] = 1\n",
    "        ev_label[i][1] = 0\n",
    "        \n",
    "    else:\n",
    "        ev_label[i][0] = 0\n",
    "        ev_label[i][1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    \n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, n):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=n)\n",
    "\n",
    "def max_pool_2x2(x, n):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding = 'SAME', name = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", shape = [None, total_pix], name='X')\n",
    "\n",
    "# float32 - for sigmoid cross entropy\n",
    "# int64 - for sparse softmax cross entropy\n",
    "#Y = tf.placeholder(tf.int64, shape = [None, 1], name='Y')\n",
    "Y = tf.placeholder(\"float\", shape = [None, 2], name='Y')\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model function for CNN.\"\"\"\n",
    "\n",
    "input_layer = tf.reshape(X, [-1, 480, 640, 3])\n",
    "\n",
    "\n",
    "conv1 = tf.layers.conv2d(\n",
    "\n",
    "    inputs=input_layer,\n",
    "    filters=48,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu,\n",
    "    name = 'conv1')\n",
    "\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2, name='pool1')\n",
    "\n",
    "\n",
    "\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=96,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu,\n",
    "    name = 'conv2')\n",
    "\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2, name='pool2')\n",
    "\n",
    "\n",
    "\n",
    "conv3 = tf.layers.conv2d(\n",
    "    inputs=pool2,\n",
    "    filters=96,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu,\n",
    "    name = 'conv3')\n",
    "\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2, name='pool3')\n",
    "\n",
    "\n",
    "\n",
    "conv4 = tf.layers.conv2d(\n",
    "    inputs=pool3,\n",
    "    filters=96,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu,\n",
    "    name = 'conv4')\n",
    "\n",
    "pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2, name='pool4')\n",
    "\n",
    "\n",
    "\n",
    "conv5 = tf.layers.conv2d(\n",
    "    inputs=pool4,\n",
    "    filters=96,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu,\n",
    "    name = 'conv5')\n",
    "\n",
    "pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2, name='pool5')\n",
    "pool5_flat = tf.reshape(pool5, [-1, 15 * 20 * 96])\n",
    "\n",
    "dense = tf.layers.dense(inputs=pool5_flat, units=1024, activation=tf.nn.relu, name='fc1')\n",
    "\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=(1-keep_prob), name='fc_drop')\n",
    "\n",
    "\n",
    "logits = tf.layers.dense(inputs=dropout, units=2, name='logits')\n",
    "y_conv = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = tf.reshape(X, [-1, height, width, channel])\n",
    "\n",
    "wc1 = weight_variable([5, 5, 3, 48], 'W1')\n",
    "bc1 = bias_variable([48], 'b1')\n",
    "hc1 = tf.nn.relu(conv2d(x_img, wc1, 'conv1') + bc1)\n",
    "hp1 = max_pool_2x2(hc1, 'max1')\n",
    "\n",
    "wc2 = weight_variable([5, 5, 48, 96], 'W2')\n",
    "bc2 = bias_variable([96], 'b2')\n",
    "hc2 = tf.nn.relu(conv2d(hp1, wc2, 'conv2') + bc2)\n",
    "hp2 = max_pool_2x2(hc2, 'max2')\n",
    "\n",
    "wc3 = weight_variable([5, 5, 96, 96], 'W3')\n",
    "bc3 = bias_variable([96], 'b3')\n",
    "hc3 = tf.nn.relu(conv2d(hp2, wc3, 'conv3') + bc3)\n",
    "hp3 = max_pool_2x2(hc3, 'max3')\n",
    "\n",
    "wc4 = weight_variable([5, 5, 96, 96], 'W4')\n",
    "bc4 = bias_variable([96], 'b4')\n",
    "hc4 = tf.nn.relu(conv2d(hp3, wc4, 'conv4') + bc4)\n",
    "hp4 = max_pool_2x2(hc4, 'max4')\n",
    "\n",
    "wc5 = weight_variable([5, 5, 96, 96], 'W5')\n",
    "bc5 = bias_variable([96], 'b5')\n",
    "hc5 = tf.nn.relu(conv2d(hp4, wc5, 'conv5') + bc5)\n",
    "hp5 = max_pool_2x2(hc5, 'max5')\n",
    "\n",
    "wf1 = weight_variable([15*20*96, 1024], 'Wf1')\n",
    "bf1 = bias_variable([1024], 'bf1')\n",
    "hf_flat = tf.reshape(hp5, [-1, 15*20*96])\n",
    "hf1 = tf.nn.relu(tf.matmul(hf_flat, wf1) + bf1)\n",
    "hf_drop = tf.nn.dropout(hf1, keep_prob)\n",
    "\n",
    "wf2 = weight_variable([1024, num_class], 'Wf2')\n",
    "bf2 = bias_variable([num_class], 'bf2')\n",
    "\n",
    "logits = tf.matmul(hf_drop, wf2) + bf2\n",
    "y_conv = tf.nn.softmax(logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05-10-13-00\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today().strftime(\"%m-%d-%H-%M\")\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816 163\n"
     ]
    }
   ],
   "source": [
    "learning_r = 0.001\n",
    "batch_s = 16\n",
    "epochs = 5\n",
    "inner_steps = int((tr_data.shape[0])/batch_s)\n",
    "total_steps = int((tr_data.shape[0]/batch_s*epochs))\n",
    "print(total_steps, inner_steps)\n",
    "disp_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_out = tf.argmax(input=logits, axis=1, name='argmax')\n",
    "#loss = tf.losses.sparse_softmax_cross_entropy(labels=Y, logits=logits)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate = 0.001).minimize(loss=loss,\n",
    "                                                                               global_step=tf.train.get_global_step())\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.sparse_softmax_cross_entropy(labels = Y, logits = logits)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate = learning_r).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_accuracy = np.zeros((len(ev_label), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625 [[0.6887257 0.6740946]\n",
      " [0.6887257 0.6740946]\n",
      " [0.6887257 0.6740946]\n",
      " [0.6887257 0.6740946]\n",
      " [0.6975883 0.7125698]\n",
      " [0.6975883 0.7125698]\n",
      " [0.6975883 0.7125698]\n",
      " [0.6887257 0.6740946]\n",
      " [0.6975883 0.7125698]\n",
      " [0.6975883 0.7125698]\n",
      " [0.6975883 0.7125698]\n",
      " [0.6887257 0.6740946]\n",
      " [0.6887257 0.6740946]\n",
      " [0.6887257 0.6740946]\n",
      " [0.6887257 0.6740946]\n",
      " [0.6975883 0.7125698]]\n",
      "0.5625 [[0.68689626 0.672862  ]\n",
      " [0.6994373  0.7138524 ]\n",
      " [0.68689626 0.672862  ]\n",
      " [0.6994373  0.7138524 ]\n",
      " [0.68689626 0.672862  ]\n",
      " [0.68689626 0.672862  ]\n",
      " [0.68689626 0.672862  ]\n",
      " [0.68689626 0.672862  ]\n",
      " [0.6994373  0.7138524 ]\n",
      " [0.6994373  0.7138524 ]\n",
      " [0.68689626 0.672862  ]\n",
      " [0.6994373  0.7138524 ]\n",
      " [0.68689626 0.672862  ]\n",
      " [0.68689626 0.672862  ]\n",
      " [0.6994373  0.7138524 ]\n",
      " [0.6994373  0.7138524 ]]\n",
      "0.6875 [[0.70364684 0.71754885]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.70364684 0.71754885]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.70364684 0.71754885]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.70364684 0.71754885]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.70364684 0.71754885]\n",
      " [0.68275666 0.6693268 ]\n",
      " [0.68275666 0.6693268 ]]\n",
      "0.8125 [[0.7097559  0.72318757]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.7097559  0.72318757]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.7097559  0.72318757]\n",
      " [0.6768097  0.6639829 ]\n",
      " [0.6768097  0.6639829 ]]\n",
      "0.625 [[0.7091065  0.7219994 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.7091065  0.7219994 ]\n",
      " [0.7091065  0.7219994 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.7091065  0.7219994 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.7091065  0.7219994 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.67743856 0.6651041 ]\n",
      " [0.7091065  0.7219994 ]\n",
      " [0.67743856 0.6651041 ]]\n",
      "0.4375 [[0.6708171  0.65904564]\n",
      " [0.7159874  0.7284528 ]\n",
      " [0.7159874  0.7284528 ]\n",
      " [0.6708171  0.65904564]\n",
      " [0.7159874  0.7284528 ]\n",
      " [0.6708171  0.65904564]\n",
      " [0.6708171  0.65904564]\n",
      " [0.7159874  0.7284528 ]\n",
      " [0.7159874  0.7284528 ]\n",
      " [0.6708171  0.65904564]\n",
      " [0.6708171  0.65904564]\n",
      " [0.7159874  0.7284528 ]\n",
      " [0.7159874  0.7284528 ]\n",
      " [0.6708171  0.65904564]\n",
      " [0.7159874  0.7284528 ]\n",
      " [0.7159874  0.7284528 ]]\n",
      "0.4375 [[0.7216326  0.73367006]\n",
      " [0.7216326  0.73367006]\n",
      " [0.66545075 0.65420264]\n",
      " [0.66545075 0.65420264]\n",
      " [0.66545075 0.65420264]\n",
      " [0.7216326  0.73367006]\n",
      " [0.7216326  0.73367006]\n",
      " [0.7216326  0.73367006]\n",
      " [0.7216326  0.73367006]\n",
      " [0.7216326  0.73367006]\n",
      " [0.66545075 0.65420264]\n",
      " [0.66545075 0.65420264]\n",
      " [0.7216326  0.73367006]\n",
      " [0.66545075 0.65420264]\n",
      " [0.66545075 0.65420264]\n",
      " [0.7216326  0.73367006]]\n",
      "0.625 [[0.66650444 0.6556831 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.7205192  0.7320696 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.7205192  0.7320696 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.7205192  0.7320696 ]\n",
      " [0.7205192  0.7320696 ]\n",
      " [0.66650444 0.6556831 ]\n",
      " [0.7205192  0.7320696 ]\n",
      " [0.7205192  0.7320696 ]]\n",
      "0.5 [[0.6680549  0.6576388 ]\n",
      " [0.7188853  0.72996294]\n",
      " [0.6680549  0.6576388 ]\n",
      " [0.6680549  0.6576388 ]\n",
      " [0.6680549  0.6576388 ]\n",
      " [0.7188853  0.72996294]\n",
      " [0.6680549  0.6576388 ]\n",
      " [0.6680549  0.6576388 ]\n",
      " [0.7188853  0.72996294]\n",
      " [0.7188853  0.72996294]\n",
      " [0.6680549  0.6576388 ]\n",
      " [0.7188853  0.72996294]\n",
      " [0.7188853  0.72996294]\n",
      " [0.7188853  0.72996294]\n",
      " [0.7188853  0.72996294]\n",
      " [0.6680549  0.6576388 ]]\n",
      "0.75 [[0.6613761  0.6514376 ]\n",
      " [0.7259608  0.73667246]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.7259608  0.73667246]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.7259608  0.73667246]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.7259608  0.73667246]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.6613761  0.6514376 ]\n",
      " [0.6613761  0.6514376 ]]\n",
      "0.25 [[0.72409636 0.7343679 ]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.66312706 0.65355855]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.66312706 0.65355855]\n",
      " [0.66312706 0.65355855]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.66312706 0.65355855]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.72409636 0.7343679 ]\n",
      " [0.72409636 0.7343679 ]]\n",
      "0.625 [[0.7284411  0.73834777]\n",
      " [0.65905654 0.64990157]\n",
      " [0.65905654 0.64990157]\n",
      " [0.7284411  0.73834777]\n",
      " [0.7284411  0.73834777]\n",
      " [0.65905654 0.64990157]\n",
      " [0.65905654 0.64990157]\n",
      " [0.7284411  0.73834777]\n",
      " [0.65905654 0.64990157]\n",
      " [0.65905654 0.64990157]\n",
      " [0.65905654 0.64990157]\n",
      " [0.7284411  0.73834777]\n",
      " [0.65905654 0.64990157]\n",
      " [0.7284411  0.73834777]\n",
      " [0.65905654 0.64990157]\n",
      " [0.65905654 0.64990157]]\n",
      "0.4375 [[0.6538593  0.64511096]\n",
      " [0.6538593  0.64511096]\n",
      " [0.73404187 0.74360776]\n",
      " [0.73404187 0.74360776]\n",
      " [0.6538593  0.64511096]\n",
      " [0.73404187 0.74360776]\n",
      " [0.6538593  0.64511096]\n",
      " [0.73404187 0.74360776]\n",
      " [0.73404187 0.74360776]\n",
      " [0.73404187 0.74360776]\n",
      " [0.73404187 0.74360776]\n",
      " [0.73404187 0.74360776]\n",
      " [0.73404187 0.74360776]\n",
      " [0.6538593  0.64511096]\n",
      " [0.6538593  0.64511096]\n",
      " [0.6538593  0.64511096]]\n",
      "0.5625 [[0.6520527  0.6436624 ]\n",
      " [0.6520527  0.6436624 ]\n",
      " [0.736003   0.74520886]\n",
      " [0.6520527  0.6436624 ]\n",
      " [0.736003   0.74520886]\n",
      " [0.6520527  0.6436624 ]\n",
      " [0.736003   0.74520886]\n",
      " [0.736003   0.74520886]\n",
      " [0.6520527  0.6436624 ]\n",
      " [0.736003   0.74520886]\n",
      " [0.6520527  0.6436624 ]\n",
      " [0.6520527  0.6436624 ]\n",
      " [0.736003   0.74520886]\n",
      " [0.6520527  0.6436624 ]\n",
      " [0.736003   0.74520886]\n",
      " [0.6520527  0.6436624 ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b42ff7f255b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         sess.run(train_step, feed_dict={X: tr_batch['data'],\n\u001b[1;32m     18\u001b[0m                                         \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtr_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                         keep_prob: 0.5})\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_count = 1\n",
    "\n",
    "for j in range(epochs):\n",
    "\n",
    "    for i in range(inner_steps):\n",
    "\n",
    "        tr_batch = {}\n",
    "\n",
    "        if i < inner_steps-1:\n",
    "            tr_batch['data'] = tr_data[i*batch_s:(i+1)*batch_s][:]\n",
    "            tr_batch['label'] = tr_label[i*batch_s:(i+1)*batch_s][:]\n",
    "\n",
    "        else:\n",
    "            tr_batch['data'] = tr_data[i*batch_s:][:]\n",
    "            tr_batch['label'] = tr_label[i*batch_s:][:]\n",
    "            \n",
    "        sess.run(train_step, feed_dict={X: tr_batch['data'],\n",
    "                                        Y: tr_batch['label'],\n",
    "                                        keep_prob: 0.5})\n",
    "\n",
    "\n",
    "        if t_count % disp_step == 0:\n",
    "            \n",
    "            loss_tr = sess.run(loss, feed_dict = {X: tr_batch['data'],\n",
    "                                                  Y: tr_batch['label'],\n",
    "                                                  keep_prob: 1.0})\n",
    "            \n",
    "            acc_tr = sess.run(accuracy, feed_dict = {X: tr_batch['data'],\n",
    "                                                     Y: tr_batch['label'],\n",
    "                                                     keep_prob: 1.0})\n",
    "            \n",
    "            #print('step %d, training accuracy %g, loss %f' % (t_count, acc_tr, loss_tr))\n",
    "            print(acc_tr, loss_tr)\n",
    "\n",
    "        t_count = t_count+1\n",
    "\n",
    "\n",
    "for k in range(len(ev_label)):\n",
    "    ev_accuracy[k] = sess.run(accuracy, feed_dict={X: ev_data[k:k+1],\n",
    "                                                   Y: ev_label[k:k+1],\n",
    "                                                   keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.saver()\n",
    "save_path = '/model/CNN2600-Vis'\n",
    "saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(ev_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.where(ev_label == 0)\n",
    "test2 = np.where(ev_label == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test1[0]), len(test2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(356/(356+297))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr_batch['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
