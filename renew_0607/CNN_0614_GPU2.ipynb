{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GPU selection (memory)\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_txt = open('./data_split/data_dir_dict_0614.txt', 'r')\n",
    "data_json = data_txt.read()\n",
    "tr_data_dir = json.loads(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data info.\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "channel = 3\n",
    "\n",
    "\n",
    "# resize\n",
    "r_w = 512\n",
    "r_h = 512\n",
    "\n",
    "total_pix = r_w * r_h * channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_data = np.zeros((len(tr_data_dir['train']), total_pix), dtype=np.float32)\n",
    "tr_label = np.zeros((len(tr_data_dir['train']), 1), dtype=np.int32)\n",
    "\n",
    "for i in range(len(tr_data_dir['train'])):\n",
    "    img = cv2.imread(tr_data_dir['train'][i][0])\n",
    "    img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "    tr_data[i,:] = img2.flatten()\n",
    "    tr_label[i] = tr_data_dir['train'][i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ev_data = np.zeros((len(tr_data_dir['test']), total_pix), dtype=np.float32)\n",
    "ev_label = np.zeros((len(tr_data_dir['test']), 1), dtype=np.int32)\n",
    "\n",
    "for i in range(len(tr_data_dir['test'])):\n",
    "    img = cv2.imread(tr_data_dir['test'][i][0])\n",
    "    img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "    ev_data[i,:] = img2.flatten()\n",
    "    ev_label[i] = tr_data_dir['test'][i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(x, n_class, dropout, reuse, is_training, width=512, height=512):\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # RGB data, 3-channel\n",
    "        input_layer = tf.reshape(x, shape=[-1, height, width, 3], name='input_layer')\n",
    "        \n",
    "        k_init = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "        \n",
    "        conv1 = tf.layers.conv2d(\n",
    "            inputs=input_layer,\n",
    "            filters=48,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=k_init,\n",
    "            name='conv1')\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2, name='pool1')\n",
    "        # height/2, width/2\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=96,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=k_init,\n",
    "            name='conv2')\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2, name='pool2')\n",
    "        # height/4, width/4\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(\n",
    "            inputs=pool2,\n",
    "            filters=96,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=k_init,\n",
    "            name='conv3')\n",
    "        pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2, name='pool3')\n",
    "        # height/8, width/8\n",
    "        \n",
    "        conv4 = tf.layers.conv2d(\n",
    "            inputs=pool3,\n",
    "            filters=96,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=k_init,\n",
    "            name='conv4')\n",
    "        pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2, name='pool4')\n",
    "        # height/16, width/16\n",
    "        \n",
    "        conv5 = tf.layers.conv2d(\n",
    "            inputs=pool4,\n",
    "            filters=96,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=k_init,\n",
    "            name='conv5')\n",
    "        pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2, name='pool5')\n",
    "        # height/32, width/32\n",
    "        \n",
    "        #pool5_flat = tf.reshape(pool5, [-1, int(height/32) * int(width/32) * 96])\n",
    "        pool5_flat = tf.contrib.layers.flatten(pool5)\n",
    "        \n",
    "        dense1 = tf.layers.dense(pool5_flat, 1024, activation=tf.nn.relu, name='dense1')\n",
    "        \n",
    "        dropout = tf.layers.dropout(dense1, rate=dropout, training=is_training, name='drop')\n",
    "        \n",
    "        # Output\n",
    "        out = tf.layers.dense(dropout, n_class, name='output')\n",
    "        out = tf.nn.softmax(out) if not is_training else out\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout = 0.5\n",
    "learning_rate = 0.0001\n",
    "batch_size = 16\n",
    "disp_step = 20\n",
    "save_step = 500\n",
    "n_classes = 2\n",
    "epochs = 30\n",
    "\n",
    "tr_steps = int(tr_data.shape[0]/batch_size*epochs)\n",
    "inner_steps = int((tr_data.shape[0])/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    reuse_vars = False\n",
    "    \n",
    "    # tf graph input\n",
    "    X = tf.placeholder(tf.float32, [None, total_pix], name='inputs')\n",
    "    Y = tf.placeholder(tf.int32, [None, 1], name='labels')\n",
    "    \n",
    "    with tf.device('/gpu:2'):\n",
    "        # cnn_model(x, n_class, dropout, re_use, is_training, width, height)\n",
    "        logits_train = cnn_model(X, n_classes, dropout, reuse=reuse_vars,\n",
    "                                 is_training=True)\n",
    "        \n",
    "        logits_test = cnn_model(X, n_classes, dropout, reuse=True,\n",
    "                                is_training=False)\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(logits=logits_train, labels=Y)\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        grads = optimizer.compute_gradients(loss)\n",
    "        \n",
    "        pred = tf.argmax(input=logits_test, axis=1)\n",
    "        correct_pred = tf.equal(pred, tf.cast(Y, tf.int64))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        #accuracy = tf.metrics.accuracy(labels=Y, predictions=pred)\n",
    "        \n",
    "        \n",
    "        prob = tf.nn.softmax(logits_test, name='softmax_tensor')\n",
    "        \n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        \n",
    "        reuse_vars = True\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'ConvNet/output/bias/Adam_1': Operation was explicitly assigned to /device:GPU:2 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: ConvNet/output/bias/Adam_1 = VariableV2[_class=[\"loc:@ConvNet/output/bias\"], container=\"\", dtype=DT_FLOAT, shape=[2], shared_name=\"\", _device=\"/device:GPU:2\"]()]]\n\nCaused by op 'ConvNet/output/bias/Adam_1', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-ff8441dc2ba9>\", line 29, in <module>\n    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 369, in minimize\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 520, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/adam.py\", line 132, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 910, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 148, in create_slot_with_initializer\n    dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 67, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 233, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 333, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py\", line 134, in variable_op_v2\n    shared_name=shared_name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 1043, in _variable_v2\n    shared_name=shared_name, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'ConvNet/output/bias/Adam_1': Operation was explicitly assigned to /device:GPU:2 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: ConvNet/output/bias/Adam_1 = VariableV2[_class=[\"loc:@ConvNet/output/bias\"], container=\"\", dtype=DT_FLOAT, shape=[2], shared_name=\"\", _device=\"/device:GPU:2\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1331\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m           tf_session.TF_ExtendGraph(self._session,\n\u001b[0;32m-> 1392\u001b[0;31m                                     graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'ConvNet/output/bias/Adam_1': Operation was explicitly assigned to /device:GPU:2 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: ConvNet/output/bias/Adam_1 = VariableV2[_class=[\"loc:@ConvNet/output/bias\"], container=\"\", dtype=DT_FLOAT, shape=[2], shared_name=\"\", _device=\"/device:GPU:2\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0090139a9ca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'ConvNet/output/bias/Adam_1': Operation was explicitly assigned to /device:GPU:2 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: ConvNet/output/bias/Adam_1 = VariableV2[_class=[\"loc:@ConvNet/output/bias\"], container=\"\", dtype=DT_FLOAT, shape=[2], shared_name=\"\", _device=\"/device:GPU:2\"]()]]\n\nCaused by op 'ConvNet/output/bias/Adam_1', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-ff8441dc2ba9>\", line 29, in <module>\n    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 369, in minimize\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 520, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/adam.py\", line 132, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py\", line 910, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 148, in create_slot_with_initializer\n    dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/slot_creator.py\", line 67, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1297, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 1093, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 439, in get_variable\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 408, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 800, in _get_single_variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2157, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2147, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\", line 2130, in default_variable_creator\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 233, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 333, in _init_from_args\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py\", line 134, in variable_op_v2\n    shared_name=shared_name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 1043, in _variable_v2\n    shared_name=shared_name, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'ConvNet/output/bias/Adam_1': Operation was explicitly assigned to /device:GPU:2 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: ConvNet/output/bias/Adam_1 = VariableV2[_class=[\"loc:@ConvNet/output/bias\"], container=\"\", dtype=DT_FLOAT, shape=[2], shared_name=\"\", _device=\"/device:GPU:2\"]()]]\n"
     ]
    }
   ],
   "source": [
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init_g)\n",
    "        sess.run(init_l)\n",
    "\n",
    "        file_n = '/models/ICROS/GPU2(1)'\n",
    "        t_count = 1\n",
    "        saver.save(sess, file_n)\n",
    "        for j in range(epochs):\n",
    "\n",
    "            for i in range(inner_steps):\n",
    "\n",
    "                tr_batch = {}\n",
    "\n",
    "                if i < inner_steps-1:\n",
    "                    tr_batch['data'] = tr_data[i*batch_size:(i+1)*batch_size][:]\n",
    "                    tr_batch['label'] = tr_label[i*batch_size:(i+1)*batch_size][:]\n",
    "\n",
    "                else:\n",
    "                    tr_batch['data'] = tr_data[i*batch_size:][:]\n",
    "                    tr_batch['label'] = tr_label[i*batch_size:][:]\n",
    "\n",
    "                sess.run(train_op, feed_dict={X: tr_batch['data'],\n",
    "                                              Y: tr_batch['label']})\n",
    "\n",
    "                if t_count % disp_step == 1:\n",
    "                    \n",
    "                    loss_tr = sess.run(loss, feed_dict = {X: tr_batch['data'],\n",
    "                                                          Y: tr_batch['label']})\n",
    "\n",
    "                    acc_tr = sess.run(accuracy, feed_dict = {X: tr_batch['data'],\n",
    "                                                             Y: tr_batch['label']})\n",
    "                    \n",
    "                    prob_tr = sess.run(prob, feed_dict = {X: tr_batch['data'],\n",
    "                                                         Y: tr_batch['label']})\n",
    "\n",
    "                    #print('step %d, training accuracy %f, loss %f' % (t_count, accuracy, loss))\n",
    "                    print('Training step: ', t_count)\n",
    "                    print('Accuracy', acc_tr)\n",
    "                    print('Probability')\n",
    "                    print(prob_tr)\n",
    "                    print('Loss: ', loss_tr)\n",
    "                    #print(acc_tr, loss_tr)\n",
    "                    \n",
    "                if t_count % save_step == 0:\n",
    "                    saver.save(sess, file_n, t_count)\n",
    "\n",
    "                t_count = t_count+1\n",
    "        \n",
    "        saver.save(sess, file_n, t_count)\n",
    "        print(\"Training is finished!!!\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        ev_accuracy = np.zeros((len(ev_label), 1))\n",
    "        for k in range(len(ev_label)):\n",
    "            ev_batch = {}\n",
    "            ev_batch['data'] = ev_data[k:(k+1)][:]\n",
    "            ev_batch['label'] = ev_label[k:(k+1)]\n",
    "            ev_accuracy[k] = sess.run(accuracy, feed_dict={X: ev_batch['data'],\n",
    "                                                           Y: ev_batch['label']})\n",
    "\n",
    "        print(np.mean(ev_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
