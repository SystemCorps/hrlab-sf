{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Trainig Templete\n",
    "## Based on Tensorlfow - CNN MNIST example\n",
    "https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/examples/tutorials/layers/cnn_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 library 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "import json\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU selection (memory)\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info.\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "channel = 3\n",
    "\n",
    "\n",
    "# resize\n",
    "r_w = 512\n",
    "r_h = 512\n",
    "\n",
    "total_pix = r_w * r_h * channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_oh_rgb/train-images/train-images_64/cut/frame144.png\n"
     ]
    }
   ],
   "source": [
    "test = open('./data_split/data_dir_dict_oh_0717.txt', 'r')\n",
    "data = test.read()\n",
    "tr_data_dir = json.loads(data)\n",
    "print(tr_data_dir[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(tr_data_dir))\n",
    "ev_data_dir = [y for x in os.walk('/data_oh_rgb/test-images/') for y in glob(os.path.join(x[0], '*.png'))]\n",
    "print(len(ev_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntr_data_dir = [y for x in os.walk('/data_oh_rgb/train-images/') for y in glob(os.path.join(x[0], '*.png'))]\\nprint(tr_data_dir[0])\\nrandom.shuffle(tr_data_dir)\\nprint(tr_data_dir[0])\\nprint(len(tr_data_dir))\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tr_data_dir = [y for x in os.walk('/data_oh_rgb/train-images/') for y in glob(os.path.join(x[0], '*.png'))]\n",
    "print(tr_data_dir[0])\n",
    "random.shuffle(tr_data_dir)\n",
    "print(tr_data_dir[0])\n",
    "print(len(tr_data_dir))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef default(o):\\n    if isinstance(o, (np.int_, np.intc, np.intp, np.int8,\\n                      np.int16, np.int32, np.int64, np.uint8,\\n                      np.uint16,np.uint32, np.uint64)):\\n        return int(o)\\n\\n    raise TypeError\\n\\nwith open('./data_split/data_dir_dict_oh_0717.txt', 'w') as file:\\n    file.write(json.dumps(tr_data_dir, default=default))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def default(o):\n",
    "    if isinstance(o, (np.int_, np.intc, np.intp, np.int8,\n",
    "                      np.int16, np.int32, np.int64, np.uint8,\n",
    "                      np.uint16,np.uint32, np.uint64)):\n",
    "        return int(o)\n",
    "\n",
    "    raise TypeError\n",
    "\n",
    "with open('./data_split/data_dir_dict_oh_0717.txt', 'w') as file:\n",
    "    file.write(json.dumps(tr_data_dir, default=default))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = np.zeros((len(tr_data_dir), total_pix), dtype=np.float32)\n",
    "tr_label = np.zeros((len(tr_data_dir), 1), dtype=np.int32)\n",
    "\n",
    "for i in range(len(tr_data_dir)):\n",
    "    img = cv2.imread(tr_data_dir[i])\n",
    "    img2 = cv2.resize(img, (r_w, r_h), interpolation=cv2.INTER_CUBIC)\n",
    "    tr_data[i,:] = img2.flatten()\n",
    "    \n",
    "    if 'normal' in tr_data_dir[i]:\n",
    "        tr_label[i] = 0\n",
    "    else:\n",
    "        tr_label[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, height, width, channels]\n",
    "    # Our Fishing net image size is 640x480 and 3-channel (RGB)\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 512, 512, 3])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 48 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 480, 640, 3]\n",
    "    # Output Tensor Shape: [batch_size, 480, 640, 48]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        \n",
    "        inputs=input_layer,\n",
    "        filters=48,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu,\n",
    "        name='conv1')\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 480, 640, 48]\n",
    "    # Output Tensor Shape: [batch_size, 240, 320, 48]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 96 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 240, 320, 48]\n",
    "    # Output Tensor Shape: [batch_size, 240, 320, 96]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 240, 320, 96]\n",
    "    # Output Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    # Output Tensor Shape: [batch_size, 120, 160, 96]    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs=pool2,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 120, 160, 96]\n",
    "    # Output Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    # Output Tensor Shape: [batch_size, 60, 80, 96]    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs=pool3,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 60, 80, 96]\n",
    "    # Output Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    # Output Tensor Shape: [batch_size, 30, 40, 96]    \n",
    "    conv5 = tf.layers.conv2d(\n",
    "        inputs=pool4,\n",
    "        filters=96,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Input Tensor Shape: [batch_size, 30, 40, 96]\n",
    "    # Output Tensor Shape: [batch_size, 15, 20, 96]\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 15, 20, 96]\n",
    "    # Output Tensor Shape: [batch_size, 15 * 20 * 96]\n",
    "    pool5_flat = tf.contrib.layers.flatten(pool5)\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 15 * 20 * 96]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool5_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 2]\n",
    "    \n",
    "    with tf.device('/GPU:3'):\n",
    "        \n",
    "        logits = tf.layers.dense(inputs=dropout, units=2)\n",
    "        \n",
    "        predictions = {\n",
    "            # Generate predictions (for PREDICT and EVAL mode)\n",
    "            \"classes\": tf.argmax(input=logits, axis=1),\n",
    "            # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "            # `logging_hook`.\n",
    "            \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "     \n",
    "\n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        # sparse_softmax_cross_entropy cannot use one-hot encoding\n",
    "\n",
    "        #loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "        # Configure the Training Op (for TRAIN mode)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.000001)\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "        # Add evaluation metrics (for EVAL mode)\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\": tf.metrics.accuracy(\n",
    "                labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining Learning Rate: 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_master': '', '_model_dir': '/models/ICROS_re_oh/Train_0/', '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_tf_random_seed': None, '_global_id_in_cluster': 0, '_is_chief': True, '_task_id': 0, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f544fa05f28>, '_task_type': 'worker', '_save_checkpoints_steps': None, '_num_ps_replicas': 0, '_service': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /models/ICROS_re_oh/Train_0/model.ckpt-2747\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2748 into /models/ICROS_re_oh/Train_0/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.11254841 0.8874516 ]\n",
      " [0.5120546  0.48794538]\n",
      " [0.73213184 0.26786816]\n",
      " [0.01974036 0.9802596 ]\n",
      " [0.5813637  0.41863635]\n",
      " [0.28206086 0.71793914]\n",
      " [0.4380312  0.5619688 ]\n",
      " [0.07586207 0.92413795]\n",
      " [0.8586532  0.14134686]\n",
      " [0.00107059 0.99892944]\n",
      " [0.35722676 0.6427733 ]\n",
      " [0.05056842 0.9494316 ]\n",
      " [0.00213729 0.99786276]\n",
      " [0.36307713 0.6369229 ]\n",
      " [0.00141029 0.9985897 ]\n",
      " [0.034463   0.965537  ]]\n",
      "INFO:tensorflow:step = 2748, loss = 0.2889395\n",
      "INFO:tensorflow:probabilities = [[0.03788323 0.96211684]\n",
      " [0.47352517 0.52647483]\n",
      " [0.973885   0.02611497]\n",
      " [0.00764039 0.9923596 ]\n",
      " [0.97016644 0.02983362]\n",
      " [0.15305378 0.84694624]\n",
      " [0.03338397 0.96661603]\n",
      " [0.34801    0.65199006]\n",
      " [0.1086364  0.8913636 ]\n",
      " [0.32956833 0.67043173]\n",
      " [0.02052004 0.9794799 ]\n",
      " [0.96085936 0.03914062]\n",
      " [0.1247093  0.87529063]\n",
      " [0.21272036 0.78727967]\n",
      " [0.01584627 0.9841538 ]\n",
      " [0.08684571 0.9131543 ]] (18.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.63828\n",
      "INFO:tensorflow:probabilities = [[0.02283334 0.9771666 ]\n",
      " [0.17757802 0.82242197]\n",
      " [0.8670715  0.13292846]\n",
      " [0.9646855  0.03531453]\n",
      " [0.00282991 0.99717015]\n",
      " [0.02949842 0.9705016 ]\n",
      " [0.02609536 0.97390467]\n",
      " [0.00074796 0.999252  ]\n",
      " [0.49265924 0.5073407 ]\n",
      " [0.00047099 0.999529  ]\n",
      " [0.00165291 0.99834704]\n",
      " [0.52041924 0.47958073]\n",
      " [0.0260483  0.9739517 ]\n",
      " [0.00001384 0.9999862 ]\n",
      " [0.9203089  0.07969113]\n",
      " [0.9151139  0.08488606]] (18.954 sec)\n",
      "INFO:tensorflow:step = 2848, loss = 0.12615603 (37.906 sec)\n",
      "INFO:tensorflow:probabilities = [[0.00398023 0.9960198 ]\n",
      " [0.76609117 0.23390882]\n",
      " [0.13575044 0.8642495 ]\n",
      " [0.04743182 0.9525682 ]\n",
      " [0.80373585 0.19626415]\n",
      " [0.00530872 0.9946913 ]\n",
      " [0.01435862 0.9856414 ]\n",
      " [0.8254691  0.17453097]\n",
      " [0.0085067  0.9914932 ]\n",
      " [0.03399038 0.9660096 ]\n",
      " [0.02899484 0.9710052 ]\n",
      " [0.9469695  0.05303047]\n",
      " [0.05677614 0.9432239 ]\n",
      " [0.00115861 0.99884146]\n",
      " [0.00028065 0.9997193 ]\n",
      " [0.00789673 0.9921033 ]] (18.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.64898\n",
      "INFO:tensorflow:probabilities = [[0.02771272 0.9722873 ]\n",
      " [0.04446116 0.95553887]\n",
      " [0.00190091 0.99809915]\n",
      " [0.00541219 0.9945878 ]\n",
      " [0.00663605 0.993364  ]\n",
      " [0.00601605 0.9939839 ]\n",
      " [0.00264917 0.9973508 ]\n",
      " [0.84113944 0.15886056]\n",
      " [0.00070498 0.999295  ]\n",
      " [0.04137416 0.95862585]\n",
      " [0.04344343 0.95655656]\n",
      " [0.00056336 0.9994367 ]\n",
      " [0.09560476 0.9043953 ]\n",
      " [0.8100285  0.1899715 ]\n",
      " [0.00326117 0.99673885]\n",
      " [0.00048968 0.9995103 ]] (18.914 sec)\n",
      "INFO:tensorflow:step = 2948, loss = 0.042007856 (37.753 sec)\n",
      "INFO:tensorflow:probabilities = [[0.03092862 0.9690713 ]\n",
      " [0.00301516 0.9969849 ]\n",
      " [0.22318794 0.7768121 ]\n",
      " [0.14566192 0.85433805]\n",
      " [0.97215784 0.02784214]\n",
      " [0.9370355  0.06296446]\n",
      " [0.9882019  0.0117981 ]\n",
      " [0.01940078 0.9805993 ]\n",
      " [0.04803013 0.95196986]\n",
      " [0.00447275 0.9955272 ]\n",
      " [0.07208322 0.92791677]\n",
      " [0.92737204 0.07262793]\n",
      " [0.00084635 0.9991536 ]\n",
      " [0.71257013 0.2874298 ]\n",
      " [0.00500673 0.99499327]\n",
      " [0.95990765 0.04009236]] (18.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.66442\n",
      "INFO:tensorflow:probabilities = [[0.00274303 0.99725705]\n",
      " [0.85551965 0.1444804 ]\n",
      " [0.00023433 0.9997657 ]\n",
      " [0.00115943 0.99884063]\n",
      " [0.00024937 0.9997507 ]\n",
      " [0.00114492 0.9988551 ]\n",
      " [0.03108433 0.96891564]\n",
      " [0.73827845 0.2617215 ]\n",
      " [0.9530206  0.04697939]\n",
      " [0.8928695  0.10713054]\n",
      " [0.00550109 0.9944989 ]\n",
      " [0.8041867  0.19581331]\n",
      " [0.6875086  0.3124914 ]\n",
      " [0.06610012 0.9338999 ]\n",
      " [0.00777714 0.99222285]\n",
      " [0.9843605  0.01563952]] (18.611 sec)\n",
      "INFO:tensorflow:step = 3048, loss = 0.084256604 (37.530 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3062 into /models/ICROS_re_oh/Train_0/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.10589473.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f544fa05780>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "#session = tf.Session(config=config)\n",
    "\n",
    "# Create the Estimator\n",
    "f_dir = \"/models/ICROS_re_oh/Train_0/\"\n",
    "#f_dir = \"/models/ICROS_re_T0_0.000001/\"\n",
    "net_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=f_dir)\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "batch_s = 16\n",
    "epochs = 10\n",
    "tr_steps = int(tr_data.shape[0]/batch_s*epochs)\n",
    "in_steps = 1\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": tr_data},\n",
    "    y=tr_label,\n",
    "    batch_size=batch_s,\n",
    "    num_epochs=epochs,\n",
    "    shuffle=False)\n",
    "net_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=tr_steps,\n",
    "    hooks=[logging_hook])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
